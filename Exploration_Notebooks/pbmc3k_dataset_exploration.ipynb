{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8083a7",
   "metadata": {},
   "source": [
    "## Step 1: Make sure we only look at T-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a0a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/_utils/__init__.py:33: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  from anndata import __version__ as anndata_version\n",
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/__init__.py:24: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n",
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/readwrite.py:16: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n",
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/datasets/_utils.py:35: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(ad.__version__).release >= (0, 8):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2700 × 32738\n",
      "    var: 'gene_ids'\n",
      "(2700, 13714)\n",
      "[0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        1.6358733 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        1.6358733 0.        0.        0.\n",
      " 0.        0.        0.        2.2265546 0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "\n",
    "adata = sc.datasets.pbmc3k()\n",
    "print(adata)  # ~2700 cells × 32738 genes\n",
    "\n",
    "# Remove genes that are expressed in less than 3 cells\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "# Make sure that sums of counts per cell are equal\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "# Some genes have very high counts, so log-transform the data\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# keep all genes\n",
    "X_full = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "print(X_full.shape)  # should be ~2700 cells × 32738 genes\n",
    "\n",
    "# inspect one cell’s expression vector\n",
    "one_cell = X_full[0]\n",
    "print(one_cell[:100])  # first 100 gene expression values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8afa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6314da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/preprocessing/_pca/__init__.py:245: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  Version(ad.__version__) < Version(\"0.9\")\n",
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/neighbors/__init__.py:430: FutureWarning: Use obsm (e.g. `k in adata.obsm` or `adata.obsm.keys() | {'u'}`) instead of AnnData.obsm_keys, AnnData.obsm_keys is deprecated and will be removed in the future.\n",
      "  if \"X_diffmap\" in adata.obsm_keys():\n",
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/rr/cq_rkbv541d24_j5xzk1s3sc0000gn/T/ipykernel_16362/595385248.py:10: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(adata, resolution=0.5)\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Compute PCA (dimensionality reduction)\n",
    "sc.pp.pca(adata, n_comps=50)\n",
    "\n",
    "# Compute neighborhood graph\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)\n",
    "\n",
    "# Cluster with the Leiden algorithm\n",
    "sc.tl.leiden(adata, resolution=0.5)\n",
    "\n",
    "# Optional: visualize clusters\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color='leiden')\n",
    "\n",
    "# Common PBMC marker genes\n",
    "markers = [\"CD3D\", \"CD3E\", \"MS4A1\", \"LYZ\", \"NKG7\", \"GNLY\", \"PPBP\"]\n",
    "\n",
    "# Visualize their expression on UMAP\n",
    "sc.pl.umap(adata, color=markers)\n",
    "\n",
    "markers = [\"CD3D\", \"CD3E\", \"MS4A1\", \"LYZ\", \"NKG7\", \"GNLY\", \"PPBP\"]\n",
    "sc.pl.matrixplot(adata, markers, groupby=\"leiden\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_t = adata[adata.obs[\"leiden\"] == \"0\"].copy()  # replace \"0\" with your T-cell cluster ID\n",
    "len(adata_t)  # number of T cells\n",
    "sc.pp.pca(adata_t, n_comps=50)\n",
    "sc.pp.neighbors(adata_t, n_neighbors=15, n_pcs=30)\n",
    "sc.tl.umap(adata_t)\n",
    "sc.tl.diffmap(adata_t)\n",
    "sc.pl.umap(adata_t, color='leiden')\n",
    "sc.pl.diffmap(adata_t, components=['1,2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b060e2",
   "metadata": {},
   "source": [
    "## Step 2: Now that we have selected just the T-Cells. Lets extract the manifold these T-Cells live on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_torch: torch.Size([662, 13714])   L_torch: torch.Size([662, 662]) nnz: 14960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholaskhorasani/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/neighbors/__init__.py:430: FutureWarning: Use obsm (e.g. `k in adata.obsm` or `adata.obsm.keys() | {'u'}`) instead of AnnData.obsm_keys, AnnData.obsm_keys is deprecated and will be removed in the future.\n",
      "  if \"X_diffmap\" in adata.obsm_keys():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, scipy.sparse as sp, torch\n",
    "\n",
    "adata_t = adata[adata.obs[\"leiden\"] == \"0\"].copy()\n",
    "\n",
    "# 1) kNN graph on your T cells (already have PCA)\n",
    "sc.pp.neighbors(adata_t, n_neighbors=15, n_pcs=30, metric=\"cosine\")\n",
    "\n",
    "# 2) affinity W, Markov P, symmetric Laplacian L\n",
    "W = adata_t.obsp[\"connectivities\"].tocsr()\n",
    "d = np.asarray(W.sum(axis=1)).ravel()\n",
    "P = sp.diags(1.0/(d+1e-12)) @ W\n",
    "S = 0.5*(P + P.T)\n",
    "L = sp.eye(W.shape[0], format=\"csr\") - S\n",
    "\n",
    "# 1) X: SciPy sparse -> dense NumPy -> torch\n",
    "X_np = adata_t.X.toarray() if sp.issparse(adata_t.X) else np.asarray(adata_t.X)\n",
    "X_torch = torch.from_numpy(X_np.astype(np.float32))  # (n_cells, n_genes)\n",
    "\n",
    "# 2) L: SciPy sparse -> COO -> torch sparse\n",
    "L_coo = L.tocoo()\n",
    "idx_np = np.vstack([L_coo.row, L_coo.col]).astype(np.int64)   # shape (2, nnz)\n",
    "val_np = L_coo.data.astype(np.float32)                        # shape (nnz,)\n",
    "indices = torch.from_numpy(idx_np)\n",
    "values  = torch.from_numpy(val_np)\n",
    "L_torch = torch.sparse_coo_tensor(indices, values, size=L_coo.shape).coalesce()\n",
    "\n",
    "print(\"X_torch:\", X_torch.shape, \"  L_torch:\", L_torch.shape, \"nnz:\", L_torch._nnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b99b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afa046b0",
   "metadata": {},
   "source": [
    "# Train Diffusion model  (Guassian Noise and Manifold Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== modular denoiser training with pluggable noise =====\n",
    "import math, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ---- noise processes ----\n",
    "class NoiseProcess:\n",
    "    \"\"\"Interface: given clean X (n_cells x d), return noised Xt and (optional) conditioning info.\"\"\"\n",
    "    def __init__(self): pass\n",
    "    def sample(self, X: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GaussianNoise(NoiseProcess):\n",
    "    def __init__(self, sigma: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "    def sample(self, X: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        return X + self.sigma * torch.randn_like(X)\n",
    "\n",
    "class ManifoldHeat(NoiseProcess):\n",
    "    \"\"\"Applies k steps of Xt <- S @ Xt ; pass S (sparse torch), steps (int) or t→steps mapping.\"\"\"\n",
    "    def __init__(self, S_sparse: torch.Tensor, steps: int = 5):\n",
    "        super().__init__()\n",
    "        assert S_sparse.is_sparse\n",
    "        self.S = S_sparse.coalesce()\n",
    "        self.steps = steps\n",
    "    def sample(self, X: torch.Tensor, steps: int = None, **kwargs) -> torch.Tensor:\n",
    "        k = self.steps if steps is None else steps\n",
    "        Xt = X\n",
    "        for _ in range(k):\n",
    "            Xt = torch.sparse.mm(self.S, Xt)\n",
    "        return Xt\n",
    "\n",
    "# ---- tiny model factory ----\n",
    "def make_mlp(d: int, hidden: int = 512) -> nn.Module:\n",
    "    return nn.Sequential(nn.Linear(d, hidden), nn.GELU(), nn.Linear(hidden, d))\n",
    "\n",
    "# ---- trainer ----\n",
    "def train_denoiser(\n",
    "    X: torch.Tensor,                                 # (n_cells, n_genes) float32\n",
    "    topk_idx: torch.Tensor,                          # 1D indices of selected genes/features\n",
    "    noise: NoiseProcess,                             # e.g., GaussianNoise(...) or ManifoldHeat(S, ...)\n",
    "    model: nn.Module = None,\n",
    "    epochs: int = 5,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    val_split: float = 0.1,\n",
    "    noise_kwargs: dict = None,                       # extra args to noise.sample (e.g., steps, sigma)\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    noise_kwargs = noise_kwargs or {}\n",
    "    X = X.to(device)\n",
    "    # select features\n",
    "    X0 = X[:, topk_idx].contiguous()\n",
    "\n",
    "    # make a noised copy using the chosen process\n",
    "    Xt = noise.sample(X, **noise_kwargs)[:, topk_idx].contiguous()\n",
    "\n",
    "    # split\n",
    "    n = X0.shape[0]\n",
    "    perm = torch.randperm(n, device=device)\n",
    "    split = int((1 - val_split) * n)\n",
    "    idx_tr, idx_va = perm[:split], perm[split:]\n",
    "\n",
    "    train_dl = DataLoader(TensorDataset(Xt[idx_tr], X0[idx_tr]), batch_size=batch_size, shuffle=True)\n",
    "    val_dl   = DataLoader(TensorDataset(Xt[idx_va], X0[idx_va]), batch_size=2*batch_size, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    d = X0.shape[1]\n",
    "    model = model or make_mlp(d)\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # (optional) resample noise each epoch for robustness:\n",
    "        Xt_full = noise.sample(X, **noise_kwargs)[:, topk_idx].contiguous()\n",
    "        Xt_tr_epoch, Xt_va_epoch = Xt_full[idx_tr], Xt_full[idx_va]\n",
    "\n",
    "        # swap datasets’ inputs\n",
    "        train_dl = DataLoader(TensorDataset(Xt_tr_epoch, X0[idx_tr]), batch_size=batch_size, shuffle=True)\n",
    "        val_dl   = DataLoader(TensorDataset(Xt_va_epoch, X0[idx_va]), batch_size=2*batch_size, shuffle=False)\n",
    "\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for x_in, x_out in train_dl:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(x_in)\n",
    "            loss = loss_fn(pred, x_out)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * x_in.size(0)\n",
    "        tr_loss /= len(train_dl.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_in, x_out in val_dl:\n",
    "                pred = model(x_in)\n",
    "                va_loss += loss_fn(pred, x_out).item() * x_in.size(0)\n",
    "        va_loss /= len(val_dl.dataset)\n",
    "        print(f\"[{noise.__class__.__name__}] epoch {epoch+1}: train MSE={tr_loss:.4f}  val MSE={va_loss:.4f}\")\n",
    "\n",
    "    # final eval on full data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Xt_eval = noise.sample(X, **noise_kwargs)[:, topk_idx]\n",
    "        X_hat   = model(Xt_eval)\n",
    "        mse_all = torch.mean((X_hat - X0)**2).item()\n",
    "\n",
    "    return model, mse_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c72431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ManifoldHeat] epoch 1: train MSE=0.8450  val MSE=0.6057\n",
      "[ManifoldHeat] epoch 2: train MSE=0.5798  val MSE=0.5671\n",
      "[ManifoldHeat] epoch 3: train MSE=0.5594  val MSE=0.5562\n",
      "[ManifoldHeat] epoch 4: train MSE=0.5521  val MSE=0.5501\n",
      "[ManifoldHeat] epoch 5: train MSE=0.5440  val MSE=0.5483\n",
      "Manifold denoiser MSE: 0.5439212322235107\n",
      "[GaussianNoise] epoch 1: train MSE=0.8412  val MSE=0.5806\n",
      "[GaussianNoise] epoch 2: train MSE=0.5503  val MSE=0.5320\n",
      "[GaussianNoise] epoch 3: train MSE=0.5176  val MSE=0.5237\n",
      "[GaussianNoise] epoch 4: train MSE=0.5024  val MSE=0.5201\n",
      "[GaussianNoise] epoch 5: train MSE=0.4894  val MSE=0.5169\n",
      "Gaussian denoiser MSE: 0.4818757176399231\n"
     ]
    }
   ],
   "source": [
    "# You already have: X_torch (n_cells x n_genes), S_torch (sparse), both on CPU\n",
    "device = \"cpu\"  # or \"cuda\" if you move tensors to GPU\n",
    "\n",
    "# pick features: top-2000 variable genes\n",
    "with torch.no_grad():\n",
    "    var = X_torch.var(dim=0, unbiased=False)\n",
    "topk = torch.topk(var, k=min(2000, X_torch.shape[1])).indices\n",
    "\n",
    "# 1) Train with MANIFOLD heat\n",
    "manifold_noise = ManifoldHeat(S_sparse=S_torch, steps=2)\n",
    "model_m, mse_m = train_denoiser(\n",
    "    X=X_torch, topk_idx=topk, noise=manifold_noise,\n",
    "    epochs=5, device=device, noise_kwargs={\"steps\": 2}\n",
    ")\n",
    "print(\"Manifold denoiser MSE:\", mse_m)\n",
    "\n",
    "# 2) Train with GAUSSIAN baseline\n",
    "gauss_noise = GaussianNoise(sigma=0.1)\n",
    "model_g, mse_g = train_denoiser(\n",
    "    X=X_torch, topk_idx=topk, noise=gauss_noise,\n",
    "    epochs=5, device=device, noise_kwargs={\"sigma\": 0.1}\n",
    ")\n",
    "print(\"Gaussian denoiser MSE:\", mse_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched sigma: 0.7717827636696748\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Use the same topk as before\n",
    "with torch.no_grad():\n",
    "    var = X_torch.var(dim=0, unbiased=False)\n",
    "topk = torch.topk(var, k=min(2000, X_torch.shape[1])).indices\n",
    "X0 = X_torch[:, topk]\n",
    "\n",
    "# Manifold corruption already defined:\n",
    "X_man = ManifoldHeat(S_sparse=S_torch, steps=5).sample(X_torch)[:, topk]\n",
    "delta_man = torch.norm(X_man - X0, dim=1).mean().item()\n",
    "\n",
    "# Solve for sigma so Gaussian has same mean L2 deviation\n",
    "def find_sigma(target, X, idx, tol=1e-4):\n",
    "    lo, hi = 1e-6, 2.0\n",
    "    for _ in range(30):\n",
    "        mid = 0.5*(lo+hi)\n",
    "        Xg = X[:, idx] + mid*torch.randn_like(X[:, idx])\n",
    "        val = torch.norm(Xg - X[:, idx], dim=1).mean().item()\n",
    "        if val < target: lo = mid\n",
    "        else: hi = mid\n",
    "    return 0.5*(lo+hi)\n",
    "\n",
    "sigma_matched = find_sigma(delta_man, X_torch, topk)\n",
    "print(\"Matched sigma:\", sigma_matched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Laplacian energy:\n",
      "  Real:       1005.293701171875\n",
      "  Manifold̂ :  -114.62344360351562\n",
      "  Gaussian̂ :  96.97181701660156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Build a dense-by-vector multiply helper for L (keep L sparse)\n",
    "def lap_energy(L_sp, X):\n",
    "    # X: (n_cells, d)\n",
    "    # Return per-cell energy using x^T L x = sum_j L_ij x_i·x_j (do via (L X) then row-wise dot)\n",
    "    LX = torch.from_numpy((L_sp @ X.numpy()).astype(np.float32)) if isinstance(X, torch.Tensor) else L_sp @ X\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        return (X * LX).sum(dim=1).cpu().numpy()\n",
    "    else:\n",
    "        return (X * LX).sum(axis=1)\n",
    "\n",
    "# Get outputs from your trained models:\n",
    "# model_m (manifold denoiser), model_g (gaussian denoiser with matched sigma)\n",
    "with torch.no_grad():\n",
    "    X_man_noised = ManifoldHeat(S_sparse=S_torch, steps=5).sample(X_torch)[:, topk]\n",
    "    Xg_noised   = X_torch[:, topk] + sigma_matched * torch.randn_like(X0)\n",
    "\n",
    "    X_hat_m = model_m(X_man_noised)\n",
    "    X_hat_g = model_g(Xg_noised)\n",
    "\n",
    "# Energies: real vs denoised\n",
    "E_real = lap_energy(L, X0)\n",
    "E_m    = lap_energy(L, X_hat_m)\n",
    "E_g    = lap_energy(L, X_hat_g)\n",
    "\n",
    "print(\"Mean Laplacian energy:\")\n",
    "print(\"  Real:      \", float(np.mean(E_real)))\n",
    "print(\"  Manifold̂ : \", float(np.mean(E_m)))\n",
    "print(\"  Gaussian̂ : \", float(np.mean(E_g)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6c3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding() got multiple values for argument 'basis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m adata_t.obsm[\u001b[33m\"\u001b[39m\u001b[33mX_denoised_manifold\u001b[39m\u001b[33m\"\u001b[39m] = model_m(X_man_noised).detach().numpy()\n\u001b[32m      4\u001b[39m adata_t.obsm[\u001b[33m\"\u001b[39m\u001b[33mX_denoised_gauss\u001b[39m\u001b[33m\"\u001b[39m] = model_g(Xg_noised).detach().numpy()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43msc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mumap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiffmap\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# overlay next step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diff_manifold_testing/venv/lib/python3.12/site-packages/scanpy/plotting/_tools/scatterplots.py:686\u001b[39m, in \u001b[36mumap\u001b[39m\u001b[34m(adata, **kwargs)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;129m@_wraps_plot_scatter\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;129m@_doc_params\u001b[39m(\n\u001b[32m    629\u001b[39m     adata_color_etc=doc_adata_color_etc,\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m )\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mumap\u001b[39m(adata: AnnData, **kwargs) -> Figure | Axes | \u001b[38;5;28mlist\u001b[39m[Axes] | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    635\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Scatter plot in UMAP basis.\u001b[39;00m\n\u001b[32m    636\u001b[39m \n\u001b[32m    637\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m \n\u001b[32m    685\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mumap\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: embedding() got multiple values for argument 'basis'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b0558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5de4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
