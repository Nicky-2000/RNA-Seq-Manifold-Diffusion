{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fca7d56",
   "metadata": {},
   "source": [
    "# Preprocess paul15 scRNA-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30f8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scientific stack\n",
    "%pip install --quiet numpy scipy pandas matplotlib scikit-learn\n",
    "\n",
    "# Scanpy for single-cell analysis\n",
    "%pip install --quiet scanpy\n",
    "\n",
    "# PHATE for manifold learning\n",
    "%pip install --quiet phate\n",
    "\n",
    "# scVI for latent representations\n",
    "%pip install --quiet scvi-tools\n",
    "\n",
    "# (Optional, but often useful)\n",
    "%pip install --quiet umap-learn  # if you ever call UMAP directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad3da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75cc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_energy.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import sparse\n",
    "import scanpy as sc  # only for type hints; not strictly necessary\n",
    "\n",
    "\n",
    "class AnnDataExpressionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps an AnnData object's X matrix (after prep()) as a PyTorch dataset.\n",
    "    Uses HVG, log-normalized expression directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ad: \"sc.AnnData\", float_dtype: np.dtype = np.float32):\n",
    "        X = ad.X\n",
    "        if sparse.issparse(X):\n",
    "            X = X.toarray()\n",
    "        X = np.asarray(X, dtype=float_dtype)\n",
    "        # Optional: mean-center features for numerical stability\n",
    "        self.mean_ = X.mean(axis=0, keepdims=True)\n",
    "        self.X = X - self.mean_\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31a2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffmap_eggfm.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def hessian_quadratic_form_batched(\n",
    "    energy_model,\n",
    "    X_batch: np.ndarray,  # (B, D) points x_b\n",
    "    V_batch: np.ndarray,  # (B, D) directions v_b\n",
    "    device: str,\n",
    "    mode: str = \"Hv_norm2\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Batched Hessian-based quadratic form q_{x_b}(v_b) for b=1..B using HVPs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    energy_model : nn.Module\n",
    "        Trained energy model: E(x) = <E_theta(x), x>.\n",
    "    X_batch : (B, D) np.ndarray\n",
    "        Batch of points x_b at which to evaluate the metric.\n",
    "    V_batch : (B, D) np.ndarray\n",
    "        Batch of directions v_b (e.g. displacements to neighbors).\n",
    "    device : str\n",
    "        \"cuda\" or \"cpu\". Assumes energy_model is already on this device.\n",
    "    mode : {\"Hv_norm2\", \"vHv\"}\n",
    "        - \"Hv_norm2\": q_b = ||H_E(x_b) v_b||^2  (>= 0, SPD-like).\n",
    "        - \"vHv\":      q_b = v_b^T H_E(x_b) v_b  (can be indefinite).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    q_batch : (B,) np.ndarray\n",
    "        Quadratic form values q_{x_b}(v_b) per pair.\n",
    "    \"\"\"\n",
    "    # Move data to device\n",
    "    x = torch.from_numpy(X_batch).to(device=device, dtype=torch.float32)\n",
    "    v = torch.from_numpy(V_batch).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    # We want per-sample Hessian-vector products, so keep x as a batch with grad\n",
    "    x = x.requires_grad_(True)\n",
    "\n",
    "    # 1) First gradient: g_b = ∇_x E(x_b) for each b\n",
    "    E: Tensor = energy_model(x).sum()  # sum over batch -> scalar\n",
    "    (g,) = torch.autograd.grad(\n",
    "        E,\n",
    "        x,\n",
    "        create_graph=True,  # we need graph for second derivative\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )  # g shape: (B, D)\n",
    "\n",
    "    # 2) For each b, gv_b = g_b · v_b; then sum over b to get scalar\n",
    "    gv = (g * v).sum(dim=1)  # (B,)\n",
    "    gv_sum = gv.sum()\n",
    "\n",
    "    # 3) Second gradient: Hv_b = ∇_x gv_b (batched via gv_sum)\n",
    "    (Hv,) = torch.autograd.grad(\n",
    "        gv_sum,\n",
    "        x,\n",
    "        create_graph=False,\n",
    "        retain_graph=False,\n",
    "        only_inputs=True,\n",
    "    )  # Hv shape: (B, D)\n",
    "\n",
    "    if mode == \"Hv_norm2\":\n",
    "        q_batch = (Hv * Hv).sum(dim=1)  # ||H v||^2 per sample\n",
    "    elif mode == \"vHv\":\n",
    "        q_batch = (v * Hv).sum(dim=1)  # v^T H v per sample\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode for hessian_quadratic_form_batched: {mode}\")\n",
    "\n",
    "    q_batch = q_batch.detach().cpu().numpy()\n",
    "    q_batch[q_batch < 1e-12] = 1e-12\n",
    "    return q_batch\n",
    "\n",
    "\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def hessian_quadratic_form_batched(\n",
    "    energy_model,\n",
    "    X_batch: np.ndarray,  # (B, D) points x_b\n",
    "    V_batch: np.ndarray,  # (B, D) directions v_b\n",
    "    device: str,\n",
    "    mode: str = \"Hv_norm2\",\n",
    ") -> np.ndarray:\n",
    "    ...\n",
    "    # unchanged from your version\n",
    "    ...\n",
    "\n",
    "\n",
    "def build_eggfm_diffmap(\n",
    "    ad_prep,\n",
    "    energy_model,\n",
    "    diff_cfg: Dict[str, Any],\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an EGGFM-aware Diffusion Map embedding using a metric induced by\n",
    "    the Hessian of the energy model via batched Hessian-vector products.\n",
    "    \"\"\"\n",
    "    X = ad_prep.X\n",
    "    if sp_sparse.issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    n_cells, D = X.shape\n",
    "\n",
    "    n_neighbors = diff_cfg.get(\"n_neighbors\", 30)\n",
    "    n_comps = diff_cfg.get(\"n_comps\", 30)\n",
    "    device = diff_cfg.get(\"device\", \"cuda\")\n",
    "    device = device if torch.cuda.is_available() else \"cpu\"\n",
    "    eps_mode = diff_cfg.get(\"eps_mode\", \"median\")\n",
    "    eps_value = float(diff_cfg.get(\"eps_value\", 1.0))\n",
    "    hvp_mode = diff_cfg.get(\"hvp_mode\", \"Hv_norm2\")\n",
    "    hvp_batch_size = diff_cfg.get(\"hvp_batch_size\", 1024)\n",
    "    t = diff_cfg.get(\"t\", 1.0)\n",
    "\n",
    "    # Move model to device once\n",
    "    energy_model = energy_model.to(device)\n",
    "    energy_model.eval()\n",
    "\n",
    "    print(f\"[EGGFM DiffMap] X shape: {X.shape}\", flush=True)\n",
    "\n",
    "    # 1) kNN for neighbor selection (Euclidean, only for neighbor indices)\n",
    "    print(\n",
    "        \"[EGGFM DiffMap] building kNN graph (euclidean for neighbor selection)...\",\n",
    "        flush=True,\n",
    "    )\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors + 1, metric=\"euclidean\")\n",
    "    nn.fit(X)\n",
    "    distances, indices = nn.kneighbors(X)\n",
    "\n",
    "    # neighbors per cell (excluding self)\n",
    "    k = indices.shape[1] - 1\n",
    "    assert k == n_neighbors, \"indices second dimension should be n_neighbors+1\"\n",
    "\n",
    "    # 2) Flatten edges\n",
    "    rows = np.repeat(np.arange(n_cells, dtype=np.int64), k)\n",
    "    cols = indices[:, 1:].reshape(-1).astype(np.int64)\n",
    "    n_edges = rows.shape[0]\n",
    "\n",
    "    print(f\"[EGGFM DiffMap] total edges (directed): {n_edges}\", flush=True)\n",
    "\n",
    "    # 3) Compute metric-aware edge lengths ℓ_ij^2 via batched HVPs\n",
    "    l2_vals = np.empty(n_edges, dtype=np.float64)\n",
    "\n",
    "    print(\n",
    "        \"[EGGFM DiffMap] computing Hessian-based edge lengths in batches...\", flush=True\n",
    "    )\n",
    "    n_batches = (n_edges + hvp_batch_size - 1) // hvp_batch_size\n",
    "\n",
    "    for b in range(n_batches):\n",
    "        start = b * hvp_batch_size\n",
    "        end = min((b + 1) * hvp_batch_size, n_edges)\n",
    "        if start >= end:\n",
    "            break\n",
    "\n",
    "        i_batch = rows[start:end]\n",
    "        j_batch = cols[start:end]\n",
    "\n",
    "        Xi_batch = X[i_batch]  # (B, D)\n",
    "        Xj_batch = X[j_batch]  # (B, D)\n",
    "        V_batch = Xj_batch - Xi_batch  # (B, D)\n",
    "\n",
    "        q_batch = hessian_quadratic_form_batched(\n",
    "            energy_model,\n",
    "            Xi_batch,\n",
    "            V_batch,\n",
    "            device=device,\n",
    "            mode=hvp_mode,\n",
    "        )\n",
    "        l2_vals[start:end] = q_batch\n",
    "\n",
    "        if (b + 1) % 50 == 0 or b == n_batches - 1:\n",
    "            print(\n",
    "                f\"  processed batch {b+1}/{n_batches} ({end} / {n_edges} edges)\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3.5) Robust cleaning + clipping of l2_vals\n",
    "    # ----------------------------------------------------\n",
    "    # keep only finite, positive values for scale estimation\n",
    "    finite_pos = np.isfinite(l2_vals) & (l2_vals > 0)\n",
    "    if not finite_pos.any():\n",
    "        print(\n",
    "            \"[EGGFM DiffMap] WARNING: no positive finite l2_vals; \"\n",
    "            f\"falling back to eps_value={eps_value}\"\n",
    "        )\n",
    "        # fill NaNs / non-positive with 1.0 so kernel isn't degenerate\n",
    "        l2_vals = np.nan_to_num(l2_vals, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "        q_low = 0.0\n",
    "        q_hi = 1.0\n",
    "        eps = eps_value\n",
    "    else:\n",
    "        l2_clean = l2_vals[finite_pos]\n",
    "        q_low = np.quantile(l2_clean, 0.05)\n",
    "        q_hi = np.quantile(l2_clean, 0.98)\n",
    "        # clip all edges to [q_low, q_hi]\n",
    "        l2_vals = np.clip(l2_vals, q_low, q_hi)\n",
    "        # replace any remaining non-finite entries with median of the clean set\n",
    "        median_clean = float(np.median(l2_clean))\n",
    "        bad = ~np.isfinite(l2_vals)\n",
    "        if bad.any():\n",
    "            l2_vals[bad] = median_clean\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        # 4) Choose kernel bandwidth ε (guarded)\n",
    "        # ------------------------------------------------\n",
    "        if eps_mode == \"median\":\n",
    "            eps = float(np.median(l2_vals[finite_pos]))\n",
    "        elif eps_mode == \"fixed\":\n",
    "            eps = eps_value\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown eps_mode: {eps_mode}\")\n",
    "\n",
    "    # final safety: ensure eps is finite and > 0\n",
    "    if not np.isfinite(eps) or eps <= 0:\n",
    "        print(\n",
    "            f\"[EGGFM DiffMap] WARNING: bad eps={eps}; \"\n",
    "            f\"falling back to eps_value={eps_value}\"\n",
    "        )\n",
    "        eps = eps_value\n",
    "\n",
    "    print(\n",
    "        f\"[EGGFM DiffMap] q_low={q_low:.4g}, q_hi={q_hi:.4g}, eps={eps:.4g}\", flush=True\n",
    "    )\n",
    "\n",
    "    # 5) Build kernel W_ij = exp(-ℓ_ij^2 / eps)\n",
    "    W_vals = np.exp(-l2_vals / eps)\n",
    "    # guard against NaNs/Infs in W_vals\n",
    "    W_vals = np.nan_to_num(W_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    W = sparse.csr_matrix((W_vals, (rows, cols)), shape=(n_cells, n_cells))\n",
    "    # Symmetrize for robustness\n",
    "    W = 0.5 * (W + W.T)\n",
    "\n",
    "    # 6) Normalize to Markov matrix P (row-stochastic)\n",
    "    d = np.array(W.sum(axis=1)).ravel()\n",
    "    d_safe = np.maximum(d, 1e-12)\n",
    "    D_inv = sparse.diags(1.0 / d_safe)\n",
    "    P = D_inv @ W\n",
    "\n",
    "    # 7) Eigendecompose P^T for diffusion map\n",
    "    k_eigs = n_comps + 1  # include trivial eigenpair\n",
    "    print(\"[EGGFM DiffMap] computing eigenvectors...\", flush=True)\n",
    "    eigvals, eigvecs = eigs(P.T, k=k_eigs, which=\"LR\")  # largest real parts\n",
    "\n",
    "    eigvals = eigvals.real\n",
    "    eigvecs = eigvecs.real\n",
    "\n",
    "    # sort by eigenvalue magnitude descending\n",
    "    order = np.argsort(-eigvals)\n",
    "    eigvals = eigvals[order]\n",
    "    eigvecs = eigvecs[:, order]\n",
    "\n",
    "    # drop trivial eigenvector (λ≈1)\n",
    "    lambdas = eigvals[1 : n_comps + 1]\n",
    "    phis = eigvecs[:, 1 : n_comps + 1]  # (n_cells, n_comps)\n",
    "\n",
    "    # Diffusion map coordinates Ψ_t(x_i) = (λ_1^t φ_1(i), ..., λ_m^t φ_m(i))\n",
    "    diff_coords = phis * (lambdas**t)\n",
    "\n",
    "    print(\"[EGGFM DiffMap] finished. Embedding shape:\", diff_coords.shape, flush=True)\n",
    "    return diff_coords.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ef47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_model.py\n",
    "\n",
    "from typing import Sequence, Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class EnergyMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    E(x) = <E_theta(x), x> where E_theta is an MLP with nonlinearities.\n",
    "\n",
    "    x is HVG, log-normalized expression (optionally mean-centered).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_genes: int,\n",
    "        hidden_dims: Sequence[int] = (512, 512, 512, 512),\n",
    "        activation: Optional[nn.Module] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if activation is None:\n",
    "            activation = nn.Softplus()\n",
    "\n",
    "        layers = []\n",
    "        in_dim = n_genes\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(activation)\n",
    "            in_dim = h\n",
    "        # final layer outputs a vector in R^D\n",
    "        layers.append(nn.Linear(in_dim, n_genes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, D)\n",
    "        returns: energy (B,)\n",
    "        \"\"\"\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        v = self.net(x)  # (B, D) = E_theta(x)\n",
    "        energy = (v * x).sum(dim=-1)  # <E_theta(x), x>\n",
    "        return energy\n",
    "\n",
    "    def score(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        score(x) ≈ ∇_x log p(x) = -∇_x E(x)\n",
    "        \"\"\"\n",
    "        x = x.clone().detach().requires_grad_(True)\n",
    "        energy = self.forward(x)  # (B,)\n",
    "        energy_sum = energy.sum()\n",
    "        (grad,) = torch.autograd.grad(\n",
    "            energy_sum,\n",
    "            x,\n",
    "            create_graph=False,\n",
    "            retain_graph=False,\n",
    "            only_inputs=True,\n",
    "        )\n",
    "        score = -grad\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_energy.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_energy_model(\n",
    "    ad_prep,  # output of prep(ad, params)\n",
    "    model_cfg: Dict[str, Any],\n",
    "    train_cfg: Dict[str, Any],\n",
    ") -> EnergyMLP:\n",
    "    \"\"\"\n",
    "    Train an energy-based model on preprocessed AnnData using denoising score matching.\n",
    "\n",
    "    model_cfg (from params['eggfm_model']), e.g.:\n",
    "        hidden_dims: [512, 512, 512, 512]\n",
    "\n",
    "    train_cfg (from params['eggfm_train']), e.g.:\n",
    "        batch_size: 2048\n",
    "        num_epochs: 50\n",
    "        lr: 1e-4\n",
    "        sigma: 0.1\n",
    "        device: \"cuda\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Device\n",
    "    device = train_cfg.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset\n",
    "    dataset = AnnDataExpressionDataset(ad_prep)\n",
    "    n_genes = dataset.X.shape[1]\n",
    "\n",
    "    # Model\n",
    "    hidden_dims = model_cfg.get(\"hidden_dims\", (512, 512, 512, 512))\n",
    "    model = EnergyMLP(\n",
    "        n_genes=n_genes,\n",
    "        hidden_dims=hidden_dims,\n",
    "    ).to(device)\n",
    "\n",
    "    # Training hyperparameters (YAML overrides defaults)\n",
    "    batch_size = int(train_cfg.get(\"batch_size\", 2048))\n",
    "    num_epochs = int(train_cfg.get(\"num_epochs\", 50))\n",
    "    lr = float(train_cfg.get(\"lr\", 1e-4))\n",
    "    sigma = float(train_cfg.get(\"sigma\", 0.1))\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in loader:\n",
    "            x = batch.to(device)  # (B, D)\n",
    "            # Sample Gaussian noise\n",
    "            eps = torch.randn_like(x)\n",
    "            y = x + sigma * eps\n",
    "            y.requires_grad_(True)\n",
    "\n",
    "            # Predicted score at y: s_theta(y) = -∇_y E(y)\n",
    "            energy = model(y)  # (B,)\n",
    "            energy_sum = energy.sum()\n",
    "            (grad_y,) = torch.autograd.grad(\n",
    "                energy_sum,\n",
    "                y,\n",
    "                create_graph=False,\n",
    "                retain_graph=False,\n",
    "                only_inputs=True,\n",
    "            )\n",
    "            s_theta = -grad_y  # (B, D)\n",
    "\n",
    "            # DSM target: -(y - x) / sigma^2\n",
    "            target = -(y - x) / (sigma**2)\n",
    "\n",
    "            # MSE over batch and dimensions\n",
    "            loss = ((s_theta - target) ** 2).sum(dim=1).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        print(\n",
    "            f\"[Energy DSM] Epoch {epoch+1}/{num_epochs}  loss={epoch_loss:.4f}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eggfm_dimred(\n",
    "    qc_ad: sc.AnnData,\n",
    "    params: Dict[str, Any],\n",
    ") -> Tuple[sc.AnnData, object]:\n",
    "    \"\"\"\n",
    "    Run EGGFM-based dimension reduction on a preprocessed AnnData.\n",
    "\n",
    "    Assumes qc_ad is already:\n",
    "      - gene-filtered\n",
    "      - HVG-selected\n",
    "      - normalized + log1p\n",
    "\n",
    "    Config sections (from params.yml):\n",
    "      eggfm_model:\n",
    "        hidden_dims: [512, 512, 512, 512]\n",
    "\n",
    "      eggfm_train:\n",
    "        batch_size: 2048\n",
    "        num_epochs: 50\n",
    "        lr: 1e-4\n",
    "        sigma: 0.1\n",
    "        device: \"cuda\"\n",
    "\n",
    "      eggfm_diffmap:\n",
    "        n_neighbors: 10\n",
    "        n_comps: 30\n",
    "        device: \"cuda\"\n",
    "        hvp_mode: \"vHv\"\n",
    "        hvp_batch_size: 2048\n",
    "        eps_mode: \"median\"\n",
    "        eps_value: 1.0\n",
    "        t: 1.0\n",
    "    \"\"\"\n",
    "\n",
    "    # Let the train/diffmap functions handle their own defaults.\n",
    "    model_cfg = params.get(\"eggfm_model\", {})\n",
    "    train_cfg = params.get(\"eggfm_train\", {})\n",
    "    diff_cfg = params.get(\"eggfm_diffmap\", {})\n",
    "\n",
    "    # 1) Train energy model\n",
    "    energy_model = train_energy_model(qc_ad, model_cfg, train_cfg)\n",
    "\n",
    "    # 2) Build EGGFM DiffMap embedding (no subsampling)\n",
    "    X_eggfm = build_eggfm_diffmap(qc_ad, energy_model, diff_cfg)\n",
    "    qc_ad.obsm[\"X_diff_eggfm\"] = X_eggfm  # make sure clustering sees this\n",
    "    qc_ad.uns[\"eggfm_meta\"] = {\n",
    "        \"hidden_dims\": model_cfg.get(\"hidden_dims\"),\n",
    "        \"batch_size\": train_cfg.get(\"batch_size\"),\n",
    "        \"lr\": train_cfg.get(\"lr\"),\n",
    "        \"sigma\": train_cfg.get(\"sigma\"),\n",
    "        \"n_neighbors\": diff_cfg.get(\"n_neighbors\"),\n",
    "        \"hvp_mode\": diff_cfg.get(\"hvp_mode\"),\n",
    "    }\n",
    "    return qc_ad, energy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643cef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def prep_for_manifolds(\n",
    "    ad: sc.AnnData,\n",
    "    min_genes: int = 200,\n",
    "    hvg_n_top_genes: int = 2000,\n",
    "    min_cells_frac: float = 0.001,\n",
    ") -> sc.AnnData:\n",
    "    \"\"\"\n",
    "    Preprocessing that mirrors your real `prep` function:\n",
    "\n",
    "      - QC metrics\n",
    "      - filter genes by min_cells_frac * n_cells\n",
    "      - filter cells by min_genes\n",
    "      - drop zero-total cells\n",
    "      - HVG selection (Seurat v3, subset=False)\n",
    "      - subset to HVGs\n",
    "      - normalize_total + log1p\n",
    "\n",
    "    No PCA here; we keep the data nonlinear for downstream DR.\n",
    "    \"\"\"\n",
    "    n_cells = ad.n_obs\n",
    "    print(\"[prep_for_manifolds] running Scanpy QC metrics\", flush=True)\n",
    "    sc.pp.calculate_qc_metrics(ad, inplace=True)\n",
    "\n",
    "    # Remove genes that are not statistically relevant (< min_cells_frac of cells)\n",
    "    min_cells = max(3, int(min_cells_frac * n_cells))\n",
    "    sc.pp.filter_genes(ad, min_cells=min_cells)\n",
    "\n",
    "    # Remove empty droplets / low-complexity cells\n",
    "    sc.pp.filter_cells(ad, min_genes=min_genes)\n",
    "\n",
    "    # Drop zero-count cells\n",
    "    totals = np.ravel(ad.X.sum(axis=1))\n",
    "    ad = ad[totals > 0, :].copy()\n",
    "\n",
    "    print(\"n_obs, n_vars (pre-HVG):\", ad.n_obs, ad.n_vars, flush=True)\n",
    "\n",
    "    # Explicit mean check, like in your script\n",
    "    X = ad.X\n",
    "    if sparse.issparse(X):\n",
    "        means = np.asarray(X.mean(axis=0)).ravel()\n",
    "    else:\n",
    "        means = np.nanmean(X, axis=0)\n",
    "\n",
    "    print(\"Means finite?\", np.all(np.isfinite(means)), flush=True)\n",
    "    print(\"Means min/max:\", np.nanmin(means), np.nanmax(means), flush=True)\n",
    "    print(\"# non-finite means:\", np.sum(~np.isfinite(means)), flush=True)\n",
    "\n",
    "    # HVG selection on raw X (no raw layer here)\n",
    "    sc.pp.highly_variable_genes(\n",
    "        ad,\n",
    "        n_top_genes=int(hvg_n_top_genes),\n",
    "        flavor=\"seurat_v3\",\n",
    "        subset=False,\n",
    "    )\n",
    "\n",
    "    ad = ad[:, ad.var[\"highly_variable\"]].copy()\n",
    "    print(\"n_obs, n_vars (post-HVG):\", ad.n_obs, ad.n_vars, flush=True)\n",
    "\n",
    "    # Now normalize/log on X\n",
    "    sc.pp.normalize_total(ad, target_sum=1e4)\n",
    "    sc.pp.log1p(ad)\n",
    "\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47cb4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "# Optional plotting / clustering helpers (for plot_result)\n",
    "# Comment these out if you don't need them.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _standardize(X: np.ndarray, axis: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Center and scale X along the given axis (like R's scale()).\n",
    "    axis=0 => column-wise standardization.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    mean = X.mean(axis=axis, keepdims=True)\n",
    "    std = X.std(axis=axis, ddof=1, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "###########################################################\n",
    "##### Utilities used in both DCOL-PCA & DCOL-CCA ##########\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def scol_matrix_order(a: np.ndarray, x: np.ndarray) -> np.ndarray | float:\n",
    "    \"\"\"\n",
    "    Python version of scol.matrix.order(a, x).\n",
    "\n",
    "    x: 1D array used to order samples.\n",
    "    a: either a vector of length n_samples or a matrix with shape (n_rows, n_samples).\n",
    "       Returns:\n",
    "         - scalar if a is a vector / single-row\n",
    "         - 1D array of length n_rows if a is 2D (row-wise DCOL distances).\n",
    "    \"\"\"\n",
    "    a = np.asarray(a)\n",
    "    x = np.asarray(x)\n",
    "    order = np.argsort(x)\n",
    "\n",
    "    # a is effectively a vector (R's \"is.null(nrow(a)) | nrow(a) == 1\")\n",
    "    if a.ndim == 1 or a.shape[0] == 1:\n",
    "        a_vec = a.ravel()[order]\n",
    "        d = np.diff(a_vec)\n",
    "        dd = np.sum(d**2)\n",
    "        return float(dd)\n",
    "\n",
    "    # otherwise: matrix case, rows = features, cols = samples\n",
    "    a_sorted = a[:, order]\n",
    "    d = np.diff(a_sorted, axis=1)\n",
    "    dd = np.sum(d**2, axis=1)  # rowSums\n",
    "    return dd\n",
    "\n",
    "\n",
    "def find_dcol(a: np.ndarray, b: np.ndarray, n_nodes: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Python version of findDCOL(a, b, nNodes).\n",
    "\n",
    "    a, b: 2D arrays with shape (n_rows, n_samples).\n",
    "          Rows are features, columns are samples.\n",
    "    n_nodes: kept for API parity; current implementation is sequential.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dcol : np.ndarray, shape (nrow(a), nrow(b))\n",
    "        Symmetric DCOL distance matrix when a and b refer to the same set.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "\n",
    "    # vector vs vector case\n",
    "    if a.ndim == 1 or a.shape[0] == 1:\n",
    "        # a, b are treated as vectors\n",
    "        return np.array(scol_matrix_order(a, b), ndmin=1)\n",
    "\n",
    "    n_a = a.shape[0]\n",
    "    n_b = b.shape[0]\n",
    "\n",
    "    # NOTE: for simplicity, this is sequential. You can parallelize these loops\n",
    "    # with multiprocessing / joblib if needed.\n",
    "    dcolab = np.zeros((n_a, n_b), dtype=float)\n",
    "    dcolba = np.zeros((n_a, n_b), dtype=float)\n",
    "\n",
    "    # dcolab[i_column] = scol_matrix_order(a, b[i, ])\n",
    "    for i in range(n_b):\n",
    "        dcolab[:, i] = scol_matrix_order(a, b[i, :])\n",
    "\n",
    "    # dcolba[j_row] = scol_matrix_order(b, a[j, ])\n",
    "    for j in range(n_a):\n",
    "        dcolba[j, :] = scol_matrix_order(b, a[j, :])\n",
    "\n",
    "    # retain the smaller entry to enforce symmetry\n",
    "    dcol = np.minimum(dcolab, dcolba)\n",
    "    return dcol\n",
    "\n",
    "\n",
    "def get_cov(\n",
    "    dcol_matrix: np.ndarray, X: np.ndarray, Y: np.ndarray\n",
    ") -> np.ndarray | float:\n",
    "    \"\"\"\n",
    "    Python version of getCov(DCOLMatrix, X, Y).\n",
    "\n",
    "    X, Y: data matrices with shape (n_samples, n_features), rows = samples.\n",
    "    dcol_matrix:\n",
    "      - scalar / length-1 => vector case (single pair).\n",
    "      - 2D matrix (p x p) => DCOL distances between features (columns of Y).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - scalar in the vector case\n",
    "    - CovMatrix (DCOL-correlation matrix), same shape as dcol_matrix in matrix case.\n",
    "    \"\"\"\n",
    "    dcol = np.asarray(dcol_matrix, float)\n",
    "    X = np.asarray(X, float)\n",
    "    Y = np.asarray(Y, float)\n",
    "\n",
    "    # Vector / scalar case\n",
    "    if dcol.ndim == 0 or (dcol.ndim == 1 and dcol.shape[0] == 1):\n",
    "        X = X.ravel()\n",
    "        Y = Y.ravel()\n",
    "        n = X.shape[0]\n",
    "        var_Y = np.var(Y, ddof=1)\n",
    "        if var_Y <= 0:\n",
    "            # Degenerate case: no variance in Y, return 0 correlation\n",
    "            return 0.0\n",
    "        value = np.sqrt(max(0.0, 1.0 - dcol.item() / (2.0 * (n - 2.0) * var_Y)))\n",
    "        return float(value)\n",
    "\n",
    "    # Matrix case\n",
    "    n = X.shape[0]\n",
    "    var_list = np.var(Y, axis=0, ddof=1)  # sample variance over samples\n",
    "\n",
    "    eps = 1e-12\n",
    "    zero_var = var_list <= eps\n",
    "    if np.any(zero_var):\n",
    "        print(\n",
    "            f\"[get_cov] {zero_var.sum()} zero-variance features; stabilizing\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    scale = np.zeros_like(var_list)\n",
    "    ok = ~zero_var\n",
    "    scale[ok] = 1.0 / (2.0 * (n - 2.0) * var_list[ok])\n",
    "\n",
    "    # eigenMapMatMult(DCOLMatrix, diag(scale)) == column-wise scaling by 'scale'\n",
    "    cov_matrix = 1.0 - dcol * scale  # broadcast scale across rows\n",
    "    cov_matrix[cov_matrix < 0] = 0.0  # clamp negs to 0 for num stability\n",
    "\n",
    "    # For zero-var features, zero out row/cl and set diag to 1\n",
    "    if np.any(zero_var):\n",
    "        cov_matrix[:, zero_var] = 0.0\n",
    "        cov_matrix[zero_var, :] = 0.0\n",
    "        idx = np.where(zero_var)[0]\n",
    "        cov_matrix[idx, idx] = 1.0\n",
    "\n",
    "    cov_matrix = np.sqrt(cov_matrix)\n",
    "    return cov_matrix\n",
    "\n",
    "\n",
    "###########################################################\n",
    "##### DCOL-PCA (feature-based and cell-based versions) ####\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def dcol_pca0(\n",
    "    X: np.ndarray,\n",
    "    k: int = 4,\n",
    "    Scale: bool = True,\n",
    "    nNodes: int = 1,\n",
    "    nPC_max: int = 100,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Python version of Dcol_PCA0(X, ...).\n",
    "    PCA with n = cells and k = principal k features\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Columns are features (genes), rows are samples (cells).    \n",
    "    k : int\n",
    "        Number of dimensions to keep for 'data.r' (visualization).\n",
    "    labels : array-like, optional\n",
    "        Group labels for plotting (unused unless you add plotting).\n",
    "    Scale : bool\n",
    "        Whether to standardize features before computing DCOL.\n",
    "    nNodes : int\n",
    "        Kept for API compatibility; current implementation is sequential.\n",
    "    nPC_max : int\n",
    "        Maximum number of principal components to compute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "      - 'cov_D'      : DCOL-based correlation matrix (p x p)\n",
    "      - 'vecs'   : eigenvectors of cov_D (p x nPC)\n",
    "      - 'vals'    : eigenvalues (nPC,)\n",
    "      - 'data_r'     : embedding (n_samples x min(k, nPC))\n",
    "      - 'X_proj'     : full projection (n_samples x nPC)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    X_o = X.copy()  # used for final projection\n",
    "\n",
    "    if Scale:\n",
    "        X = _standardize(X, axis=0)  # column-wise (features)\n",
    "\n",
    "    # DCOL matrix over features: findDCOL(t(X), t(X))\n",
    "    DcolMatrix = find_dcol(X.T, X.T, n_nodes=nNodes)\n",
    "    cov_D = get_cov(DcolMatrix, X, X)  # DCOL-correlation matrix\n",
    "\n",
    "    # Suppose cov_D is the matrix passed to eigsh\n",
    "    print(\"[dcol_pca] cov_D finite?\", np.isfinite(cov_D).all(), flush=True)\n",
    "    print(\"[dcol_pca] cov_D min/max:\", np.nanmin(cov_D), np.nanmax(cov_D), flush=True)\n",
    "\n",
    "    # Eigen-decomposition (like RSpectra::eigs_sym on symmetric cov_D)\n",
    "    p = cov_D.shape[0]\n",
    "    nPC = min(nPC_max, p)\n",
    "\n",
    "    # Enforce symmetry and remove NaN/Inf just in case\n",
    "    cov_D = 0.5 * (cov_D + cov_D.T)\n",
    "    cov_D = np.nan_to_num(cov_D, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Add tiny diagonal jitter for numerical stablility\n",
    "    cov_D.flat[:: p + 1] += 1e-8\n",
    "\n",
    "    if p <= nPC + 10:\n",
    "        # small matrix: use dense eigh\n",
    "        vals, vecs = np.linalg.eigh(cov_D)\n",
    "        idx = np.argsort(vals)[::-1][:nPC]\n",
    "        vals = vals[idx]\n",
    "        vecs = vecs[:, idx]\n",
    "    else:\n",
    "        # large matrix: sparse eigensolver\n",
    "        vals, vecs = eigsh(cov_D, k=nPC, which=\"LM\")\n",
    "        idx = np.argsort(vals)[::-1]\n",
    "        vals = vals[idx]\n",
    "        vecs = vecs[:, idx]\n",
    "\n",
    "    # Project original (unscaled) X onto eigenvectors\n",
    "    X_proj = X_o @ vecs  # (n_samples x nPC)\n",
    "    data_r = X_proj[:, : min(k, X_proj.shape[1])]\n",
    "\n",
    "    # You can add plotting here if image == 1 (using matplotlib).\n",
    "\n",
    "    return {\n",
    "        \"cov_D\": cov_D,\n",
    "        \"vecs\": vecs,\n",
    "        \"vals\": vals,\n",
    "        \"data_r\": data_r,\n",
    "        \"X_proj\": X_proj,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66eb3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple, Sequence, Optional\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def compute_manifolds(\n",
    "    adata: sc.AnnData,\n",
    "    params: Dict[str, Any],\n",
    "    n_pcs: int = 50,\n",
    "    seed: int = 0,\n",
    "    label_key: str | None = None,\n",
    "    n_neighbors: int = 30,\n",
    "    umap_min_dist: float = 0.3,\n",
    "    methods: Optional[Sequence[str]] = None,\n",
    ") -> Tuple[sc.AnnData, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Compute a small panel of embeddings on `adata` and optionally display\n",
    "    a UMAP for each manifold inline (Jupyter style).\n",
    "\n",
    "    methods:\n",
    "        Which embeddings to compute. Possible keys:\n",
    "          - \"dcol_pca\"\n",
    "          - \"pca\"\n",
    "          - \"diffmap_pca\"\n",
    "          - \"diffmap_dcol\"\n",
    "          - \"diffmap_eggfm\"\n",
    "          - \"phate\"\n",
    "          - \"scvi\"\n",
    "        If None, all are computed.\n",
    "\n",
    "    Embeddings stored / returned:\n",
    "      - dcol_pca       -> adata.obsm[\"X_dcolpca\"]\n",
    "      - pca            -> adata.obsm[\"X_pca\"]\n",
    "      - diffmap_pca    -> adata.obsm[\"X_diff_pca\"]\n",
    "      - diffmap_dcol   -> adata.obsm[\"X_diff_dcol\"]\n",
    "      - diffmap_eggfm  -> adata.obsm[\"X_diff_eggfm\"]\n",
    "      - phate          -> adata.obsm[\"X_phate\"]\n",
    "      - scvi           -> adata.obsm[\"X_scvi\"]\n",
    "    \"\"\"\n",
    "    if methods is None:\n",
    "        methods_set = {\n",
    "            \"dcol_pca\",\n",
    "            \"pca\",\n",
    "            \"diffmap_pca\",\n",
    "            \"diffmap_dcol\",\n",
    "            \"diffmap_eggfm\",\n",
    "            \"phate\",\n",
    "            \"scvi\",\n",
    "        }\n",
    "    else:\n",
    "        methods_set = set(methods)\n",
    "\n",
    "    embeddings: Dict[str, np.ndarray] = {}\n",
    "    spec = params.get(\"spec\", {})\n",
    "    dcol_max_cells = int(spec.get(\"dcol_max_cells\", 3000))\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 0) DCOL-PCA (fit on subset, project all cells)\n",
    "    # ----------------------------------------------------\n",
    "    if \"dcol_pca\" in methods_set or \"diffmap_dcol\" in methods_set:\n",
    "        if adata.n_obs > dcol_max_cells:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            idx = np.sort(rng.choice(adata.n_obs, size=dcol_max_cells, replace=False))\n",
    "            ad_dcol = adata[idx, :].copy()\n",
    "            print(\n",
    "                f\"[dcol_pca] subsampled {dcol_max_cells}/{adata.n_obs} cells for DCOL-PCA\",\n",
    "                flush=True,\n",
    "            )\n",
    "        else:\n",
    "            ad_dcol = adata.copy()\n",
    "            print(f\"[dcol_pca] using all {adata.n_obs} cells for DCOL-PCA\", flush=True)\n",
    "\n",
    "        X_sub = ad_dcol.X\n",
    "        if sparse.issparse(X_sub):\n",
    "            X_sub = X_sub.toarray()\n",
    "\n",
    "        K_sub = dcol_pca0(X_sub, nPC_max=n_pcs, Scale=True)\n",
    "        vecs_dcol = K_sub[\"vecs\"]  # (n_genes x n_pcs)\n",
    "\n",
    "        X_full = adata.X\n",
    "        if sparse.issparse(X_full):\n",
    "            X_full = X_full.toarray()\n",
    "        X_proj_full_dcol = X_full @ vecs_dcol\n",
    "        adata.obsm[\"X_dcolpca\"] = X_proj_full_dcol\n",
    "        embeddings[\"dcol_pca\"] = X_proj_full_dcol\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1) PCA (baseline)\n",
    "    # ----------------------------------------------------\n",
    "    if \"pca\" in methods_set or \"diffmap_pca\" in methods_set:\n",
    "        if \"X_pca\" not in adata.obsm_keys():\n",
    "            sc.tl.pca(adata, n_comps=n_pcs, svd_solver=\"arpack\", random_state=seed)\n",
    "        embeddings[\"pca\"] = adata.obsm[\"X_pca\"].copy()\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2) Diffusion maps (PCA prior & DCOL prior)\n",
    "    # ----------------------------------------------------\n",
    "    if \"diffmap_pca\" in methods_set:\n",
    "        sc.pp.neighbors(\n",
    "            adata,\n",
    "            n_neighbors=n_neighbors,\n",
    "            use_rep=\"X_pca\",\n",
    "            random_state=seed,\n",
    "        )\n",
    "        sc.tl.diffmap(adata, n_comps=n_pcs)\n",
    "        X_diff_pca = adata.obsm[\"X_diffmap\"][:, :n_pcs].copy()\n",
    "        adata.obsm[\"X_diff_pca\"] = X_diff_pca\n",
    "        embeddings[\"diffmap_pca\"] = X_diff_pca\n",
    "\n",
    "    if \"diffmap_dcol\" in methods_set:\n",
    "        sc.pp.neighbors(\n",
    "            adata,\n",
    "            n_neighbors=n_neighbors,\n",
    "            use_rep=\"X_dcolpca\",\n",
    "            random_state=seed,\n",
    "        )\n",
    "        sc.tl.diffmap(adata, n_comps=n_pcs)\n",
    "        X_diff_dcol = adata.obsm[\"X_diffmap\"][:, :n_pcs].copy()\n",
    "        adata.obsm[\"X_diff_dcol\"] = X_diff_dcol\n",
    "        embeddings[\"diffmap_dcol\"] = X_diff_dcol\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3) EGGFM Diffmap (for ablations)\n",
    "    # ----------------------------------------------------\n",
    "    if \"diffmap_eggfm\" in methods_set:\n",
    "        adata, _ = run_eggfm_dimred(adata, params)\n",
    "        if \"X_diff_eggfm\" in adata.obsm:\n",
    "            X_diff_eggfm = adata.obsm[\"X_diff_eggfm\"]\n",
    "            if X_diff_eggfm.shape[1] > n_pcs:\n",
    "                X_diff_eggfm = X_diff_eggfm[:, :n_pcs]\n",
    "                adata.obsm[\"X_diff_eggfm\"] = X_diff_eggfm\n",
    "            embeddings[\"diffmap_eggfm\"] = X_diff_eggfm\n",
    "        else:\n",
    "            print(\"[eggfm] X_diff_eggfm not found in adata.obsm; skipping.\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 4) PHATE (optional)\n",
    "    # ----------------------------------------------------\n",
    "    if \"phate\" in methods_set:\n",
    "        try:\n",
    "            import phate\n",
    "\n",
    "            X_ph = adata.X\n",
    "            if sparse.issparse(X_ph):\n",
    "                X_ph = X_ph.toarray()\n",
    "\n",
    "            phate_op = phate.PHATE(\n",
    "                n_components=n_pcs,\n",
    "                n_jobs=-1,\n",
    "                random_state=seed,\n",
    "            )\n",
    "            X_phate = phate_op.fit_transform(X_ph)\n",
    "            adata.obsm[\"X_phate\"] = X_phate\n",
    "            embeddings[\"phate\"] = X_phate\n",
    "        except ImportError:\n",
    "            print(\"[warn] phate not installed; skipping PHATE embedding\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 5) scVI latent space (optional)\n",
    "    # ----------------------------------------------------\n",
    "    if \"scvi\" in methods_set:\n",
    "        try:\n",
    "            import scvi\n",
    "\n",
    "            scvi.model.SCVI.setup_anndata(adata)\n",
    "            scvi_model = scvi.model.SCVI(adata, n_latent=min(10, n_pcs))\n",
    "            scvi_model.train(\n",
    "                max_epochs=200,\n",
    "                check_val_every_n_epoch=10,\n",
    "                plan_kwargs={\"lr\": 1e-3},\n",
    "            )\n",
    "            X_scvi = scvi_model.get_latent_representation()\n",
    "            adata.obsm[\"X_scvi\"] = X_scvi\n",
    "            embeddings[\"scvi\"] = X_scvi\n",
    "        except ImportError:\n",
    "            print(\"[warn] scvi-tools not installed; skipping scVI latent\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 6) UMAPs for each embedding (inline, Jupyter style)\n",
    "    # ----------------------------------------------------\n",
    "    if label_key is not None:\n",
    "        methods_umap = {\n",
    "            \"X_pca\": \"PCA\",\n",
    "            \"X_dcolpca\": \"DCOL-PCA\",\n",
    "            \"X_diff_pca\": \"Diffmap (PCA)\",\n",
    "            \"X_diff_dcol\": \"Diffmap (DCOL)\",\n",
    "            \"X_diff_eggfm\": \"Diffmap (EGGFM)\",\n",
    "            \"X_phate\": \"PHATE\",\n",
    "            \"X_scvi\": \"scVI\",\n",
    "        }\n",
    "\n",
    "        for obsm_key, title in methods_umap.items():\n",
    "            # only plot if method was requested and exists\n",
    "            base_name = obsm_key.replace(\"X_\", \"\").lower()\n",
    "            if \"diff_eggfm\" in base_name:\n",
    "                needed = \"diffmap_eggfm\"\n",
    "            elif \"diff_pca\" in base_name:\n",
    "                needed = \"diffmap_pca\"\n",
    "            elif \"diff_dcol\" in base_name:\n",
    "                needed = \"diffmap_dcol\"\n",
    "            elif \"dcolpca\" in base_name:\n",
    "                needed = \"dcol_pca\"\n",
    "            else:\n",
    "                needed = base_name\n",
    "\n",
    "            if needed not in methods_set:\n",
    "                continue\n",
    "            if obsm_key not in adata.obsm:\n",
    "                print(f\"[UMAP] skipping {obsm_key}, not in adata.obsm\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[UMAP] {title} → UMAP({label_key})\")\n",
    "            ad_tmp = adata.copy()\n",
    "            ad_tmp.obsm[\"X_tmp\"] = adata.obsm[obsm_key]\n",
    "\n",
    "            sc.pp.neighbors(\n",
    "                ad_tmp,\n",
    "                n_neighbors=n_neighbors,\n",
    "                use_rep=\"X_tmp\",\n",
    "                random_state=seed,\n",
    "            )\n",
    "            sc.tl.umap(ad_tmp, min_dist=umap_min_dist, random_state=seed)\n",
    "\n",
    "            sc.pl.umap(\n",
    "                ad_tmp,\n",
    "                color=label_key,\n",
    "                title=f\"{title} → UMAP ({label_key})\",\n",
    "                frameon=False,\n",
    "                show=True,\n",
    "            )\n",
    "\n",
    "    return adata, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8894234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4b1f693134a1eb290d0afdb09322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/9.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prep_for_manifolds] running Scanpy QC metrics\n",
      "n_obs, n_vars (pre-HVG): 2730 3451\n",
      "Means finite? True\n",
      "Means min/max: 0.0043956046 26.31099\n",
      "# non-finite means: 0\n",
      "n_obs, n_vars (post-HVG): 2730 2000\n",
      "[Energy DSM] Epoch 1/50  loss=0.0000\n",
      "[Energy DSM] Epoch 2/50  loss=0.0000\n",
      "[Energy DSM] Epoch 3/50  loss=0.0000\n",
      "[Energy DSM] Epoch 4/50  loss=0.0000\n",
      "[Energy DSM] Epoch 5/50  loss=0.0000\n",
      "[Energy DSM] Epoch 6/50  loss=0.0000\n",
      "[Energy DSM] Epoch 7/50  loss=0.0000\n",
      "[Energy DSM] Epoch 8/50  loss=0.0000\n",
      "[Energy DSM] Epoch 9/50  loss=0.0000\n",
      "[Energy DSM] Epoch 10/50  loss=0.0000\n",
      "[Energy DSM] Epoch 11/50  loss=0.0000\n",
      "[Energy DSM] Epoch 12/50  loss=0.0000\n",
      "[Energy DSM] Epoch 13/50  loss=0.0000\n",
      "[Energy DSM] Epoch 14/50  loss=0.0000\n",
      "[Energy DSM] Epoch 15/50  loss=0.0000\n",
      "[Energy DSM] Epoch 16/50  loss=0.0000\n",
      "[Energy DSM] Epoch 17/50  loss=0.0000\n",
      "[Energy DSM] Epoch 18/50  loss=0.0000\n",
      "[Energy DSM] Epoch 19/50  loss=0.0000\n",
      "[Energy DSM] Epoch 20/50  loss=0.0000\n",
      "[Energy DSM] Epoch 21/50  loss=0.0000\n",
      "[Energy DSM] Epoch 22/50  loss=0.0000\n",
      "[Energy DSM] Epoch 23/50  loss=0.0000\n",
      "[Energy DSM] Epoch 24/50  loss=0.0000\n",
      "[Energy DSM] Epoch 25/50  loss=0.0000\n",
      "[Energy DSM] Epoch 26/50  loss=0.0000\n",
      "[Energy DSM] Epoch 27/50  loss=0.0000\n",
      "[Energy DSM] Epoch 28/50  loss=0.0000\n",
      "[Energy DSM] Epoch 29/50  loss=0.0000\n",
      "[Energy DSM] Epoch 30/50  loss=0.0000\n",
      "[Energy DSM] Epoch 31/50  loss=0.0000\n",
      "[Energy DSM] Epoch 32/50  loss=0.0000\n",
      "[Energy DSM] Epoch 33/50  loss=0.0000\n",
      "[Energy DSM] Epoch 34/50  loss=0.0000\n",
      "[Energy DSM] Epoch 35/50  loss=0.0000\n",
      "[Energy DSM] Epoch 36/50  loss=0.0000\n",
      "[Energy DSM] Epoch 37/50  loss=0.0000\n",
      "[Energy DSM] Epoch 38/50  loss=0.0000\n",
      "[Energy DSM] Epoch 39/50  loss=0.0000\n",
      "[Energy DSM] Epoch 40/50  loss=0.0000\n",
      "[Energy DSM] Epoch 41/50  loss=0.0000\n",
      "[Energy DSM] Epoch 42/50  loss=0.0000\n",
      "[Energy DSM] Epoch 43/50  loss=0.0000\n",
      "[Energy DSM] Epoch 44/50  loss=0.0000\n",
      "[Energy DSM] Epoch 45/50  loss=0.0000\n",
      "[Energy DSM] Epoch 46/50  loss=0.0000\n",
      "[Energy DSM] Epoch 47/50  loss=0.0000\n",
      "[Energy DSM] Epoch 48/50  loss=0.0000\n",
      "[Energy DSM] Epoch 49/50  loss=0.0000\n",
      "[Energy DSM] Epoch 50/50  loss=0.0000\n",
      "[EGGFM DiffMap] X shape: (2730, 2000)\n",
      "[EGGFM DiffMap] building kNN graph (euclidean for neighbor selection)...\n",
      "[EGGFM DiffMap] total edges (directed): 27300\n",
      "[EGGFM DiffMap] computing Hessian-based edge lengths in batches...\n",
      "  processed batch 7/7 (27300 / 27300 edges)\n",
      "[EGGFM DiffMap] WARNING: no positive finite l2_vals; falling back to eps_value=1.0\n",
      "[EGGFM DiffMap] q_low=0, q_hi=1, eps=1\n",
      "[EGGFM DiffMap] computing eigenvectors...\n",
      "[EGGFM DiffMap] finished. Embedding shape: (2730, 30)\n",
      "[UMAP] Diffmap (EGGFM) → UMAP(paul15_clusters)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1345028458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mlabel_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"paul15_clusters\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m adata, embeddings = compute_manifolds(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1483946888.py\u001b[0m in \u001b[0;36mcompute_manifolds\u001b[0;34m(adata, params, n_pcs, seed, label_key, n_neighbors, umap_min_dist, methods)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mad_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_tmp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobsm_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             sc.pp.neighbors(\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0mad_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scanpy/neighbors/__init__.py\u001b[0m in \u001b[0;36mneighbors\u001b[0;34m(adata, n_neighbors, n_pcs, use_rep, knn, method, transformer, metric, metric_kwds, random_state, key_added, copy)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_as_actual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     neighbors.compute_neighbors(\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mn_pcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_pcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scanpy/neighbors/__init__.py\u001b[0m in \u001b[0;36mcompute_neighbors\u001b[0;34m(self, n_neighbors, n_pcs, use_rep, knn, method, transformer, metric, metric_kwds, random_state)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"umap\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             self._connectivities = _connectivity.umap(\n\u001b[0m\u001b[1;32m    603\u001b[0m                 \u001b[0mknn_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mknn_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scanpy/neighbors/_connectivity.py\u001b[0m in \u001b[0;36mumap\u001b[0;34m(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# umap 0.5.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"Tensorflow not installed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzzy_simplicial_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/umap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplefilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mumap_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m from umap.utils import (\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/umap/sparse.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_NUMERIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/umap/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i4(i8[:])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtau_rand_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"A fast (pseudo)-random number generator.\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtypeinfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numba:compile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mev_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m                         \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mfolded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_failed_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         cres = compiler.compile_extra(self.targetdescr.typing_context,\n\u001b[0m\u001b[1;32m    108\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetdescr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \"\"\"\n\u001b[0;32m--> 742\u001b[0;31m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[0m\u001b[1;32m    743\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, typingctx, targetctx, library, args, return_type, flags, locals)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Make sure the environment is reloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mtypingctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mtargetctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/context.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_additional_registries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Some extensions may have augmented the builtin registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_builtins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexplain_function_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/context.py\u001b[0m in \u001b[0;36m_load_builtins\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsafe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meh\u001b[0m                    \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_registry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_additional_registries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/context.py\u001b[0m in \u001b[0;36minstall_registry\u001b[0;34m(self, registry)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_for_this_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgty\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_registrations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'globals'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mexisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/templates.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OverloadAttributeTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/templates.py\u001b[0m in \u001b[0;36m_init_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mregistry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarArg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/typing/templates.py\u001b[0m in \u001b[0;36m_get_target_registry\u001b[0;34m(self, reason)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;31m# In case the target has swapped, e.g. cuda borrowing cpu, refresh to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;31m# populate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mtgtctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuiltin_registry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtgtctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltin_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/base.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# load target specific registries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_additional_registries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# Populate the builtin registry, this has to happen after loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/core/cpu.py\u001b[0m in \u001b[0;36mload_additional_registries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# load 3rd party extensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentrypoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# fix for #8940\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "# 1) Load data\n",
    "adata = sc.datasets.paul15()\n",
    "\n",
    "# 2) Preprocess in a way that mirrors your real Weinreb prep\n",
    "adata = prep_for_manifolds(\n",
    "    adata,\n",
    "    min_genes=200,  # match params[\"qc\"][\"min_genes\"] if you want\n",
    "    hvg_n_top_genes=2000,  # match params[\"hvg_n_top_genes\"]\n",
    ")\n",
    "\n",
    "# 3) Compute manifolds + UMAPs using DCOL, Diffmap(PCA/DCOL/EGGFM), PHATE, scVI\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"seed\": 7,\n",
    "    \"hvg_n_top_genes\": 2000,\n",
    "    \"spec\": {\n",
    "        \"n_pcs\": 20,\n",
    "        \"dcol_max_cells\": 3000,\n",
    "        \"ari_label_key\": \"Cell type annotation\",  # must match adata.obs column\n",
    "        \"ari_n_dims\": 10,\n",
    "    },\n",
    "    \"qc\": {\n",
    "        \"min_cells\": 500,\n",
    "        \"min_genes\": 200,\n",
    "        \"max_pct_mt\": 15,\n",
    "    },\n",
    "    \"eggfm_model\": {\n",
    "        \"hidden_dims\": [512, 512, 512, 512],\n",
    "    },\n",
    "    \"eggfm_train\": {\n",
    "        \"batch_size\": 4096,\n",
    "        \"num_epochs\": 50,\n",
    "        \"lr\": 1e-4,\n",
    "        \"sigma\": 0.1,\n",
    "        \"device\": \"cuda\",\n",
    "    },\n",
    "    \"eggfm_diffmap\": {\n",
    "        \"n_neighbors\": 10,\n",
    "        \"n_comps\": 30,\n",
    "        \"device\": \"cuda\",\n",
    "        \"hvp_mode\": \"vHv\",\n",
    "        \"hvp_batch_size\": 4096,\n",
    "        \"eps_mode\": \"median\",\n",
    "        \"eps_value\": 1.0,\n",
    "        \"t\": 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "label_key = \"paul15_clusters\"\n",
    "\n",
    "adata, embeddings = compute_manifolds(\n",
    "    adata,\n",
    "    params=params,\n",
    "    n_pcs=50,\n",
    "    seed=0,\n",
    "    label_key=label_key,\n",
    "    n_neighbors=30,\n",
    "    umap_min_dist=0.3,\n",
    "    methods=[\"diffmap_eggfm\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333118e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_embeddings(\n",
    "    embeddings: dict[str, np.ndarray],\n",
    "    labels: np.ndarray,\n",
    "    n_clusters: int,\n",
    "    n_seeds: int = 10,\n",
    "    seed: int = 0,\n",
    "    ari_k: int = 10,\n",
    "    plot: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate a dict of embeddings via KMeans + ARI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dict[str, np.ndarray]\n",
    "        Mapping from method name -> embedding array (n_cells x d).\n",
    "    labels : np.ndarray\n",
    "        Ground-truth labels (length n_cells).\n",
    "    n_clusters : int\n",
    "        Number of clusters for KMeans (typically == # unique labels).\n",
    "    n_seeds : int\n",
    "        Number of KMeans random seeds to use for each embedding.\n",
    "    seed : int\n",
    "        Base random seed; seeds used are seed, seed+1, ..., seed+n_seeds-1.\n",
    "    ari_k : int\n",
    "        Number of leading dimensions to use from each embedding.\n",
    "    plot : bool\n",
    "        If True, show a bar plot of mean ARI with error bars (± std).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Columns: [\"method\", \"mean_ari\", \"std_ari\"] sorted by mean_ari desc.\n",
    "    \"\"\"\n",
    "    rows: list[dict[str, float | str]] = []\n",
    "\n",
    "    for name, emb in embeddings.items():\n",
    "        emb = np.asarray(emb)\n",
    "        if emb.ndim != 2:\n",
    "            print(f\"[evaluate_embeddings] skipping {name}: emb.ndim={emb.ndim}\")\n",
    "            continue\n",
    "        if emb.shape[0] != labels.shape[0]:\n",
    "            print(\n",
    "                f\"[evaluate_embeddings] skipping {name}: \"\n",
    "                f\"n_cells mismatch (emb={emb.shape[0]}, labels={labels.shape[0]})\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        k_eff = min(ari_k, emb.shape[1])\n",
    "        X_use = emb[:, :k_eff]\n",
    "\n",
    "        scores = []\n",
    "        for s in range(seed, seed + n_seeds):\n",
    "            km = KMeans(n_clusters=n_clusters, n_init=10, random_state=s)\n",
    "            km.fit(X_use)\n",
    "            ari = adjusted_rand_score(labels, km.labels_)\n",
    "            scores.append(ari)\n",
    "\n",
    "        scores = np.asarray(scores, float)\n",
    "        mean_ari = float(scores.mean())\n",
    "        std_ari = float(scores.std())\n",
    "\n",
    "        print(f\"[ARI] {name:15s}: mean={mean_ari:0.4f}, std={std_ari:0.4f}\")\n",
    "        rows.append({\"method\": name, \"mean_ari\": mean_ari, \"std_ari\": std_ari})\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"[evaluate_embeddings] No valid embeddings to evaluate.\")\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values(\"mean_ari\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.bar(df[\"method\"], df[\"mean_ari\"], yerr=df[\"std_ari\"], capsize=4)\n",
    "        ax.set_ylabel(\"Adjusted Rand Index\")\n",
    "        ax.set_title(f\"Clustering ARI across embeddings (k={ari_k}, seeds={n_seeds})\")\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "# assume these are already imported from your codebase:\n",
    "# from your_module import compute_manifolds, evaluate_embeddings\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load data + labels once\n",
    "# -------------------------------------------------------------------\n",
    "adata = sc.read_h5ad(\"data/prep/qc_paul15.h5ad\")  # adjust path\n",
    "label_key = \"paul15_clusters\"\n",
    "labels = adata.obs[label_key].to_numpy()\n",
    "n_clusters = np.unique(labels).size\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Baseline params (the dict you showed earlier)\n",
    "# -------------------------------------------------------------------\n",
    "base_params = {\n",
    "    \"seed\": 7,\n",
    "    \"hvg_n_top_genes\": 2000,\n",
    "    \"spec\": {\n",
    "        \"n_pcs\": 20,\n",
    "        \"dcol_max_cells\": 3000,\n",
    "        \"ari_label_key\": label_key,\n",
    "        \"ari_n_dims\": 10,\n",
    "    },\n",
    "    \"qc\": {\n",
    "        \"min_cells\": 500,\n",
    "        \"min_genes\": 200,\n",
    "        \"max_pct_mt\": 15,\n",
    "    },\n",
    "    \"eggfm_model\": {\n",
    "        \"hidden_dims\": [512, 512, 512, 512],\n",
    "    },\n",
    "    \"eggfm_train\": {\n",
    "        \"batch_size\": 4096,\n",
    "        \"num_epochs\": 50,\n",
    "        \"lr\": 1e-3,\n",
    "        \"sigma\": 0.1,\n",
    "        \"device\": \"cuda\",\n",
    "    },\n",
    "    \"eggfm_diffmap\": {\n",
    "        \"n_neighbors\": 30,\n",
    "        \"n_comps\": 30,\n",
    "        \"device\": \"cuda\",\n",
    "        \"hvp_mode\": \"Hv_norm2\",\n",
    "        \"hvp_batch_size\": 4096,\n",
    "        \"eps_mode\": \"median\",\n",
    "        \"eps_value\": 1.0,\n",
    "        \"t\": 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Ablation grids (per-family, not all combined)\n",
    "# -------------------------------------------------------------------\n",
    "abl_n_neighbors = [10, 20, 40, 60]\n",
    "abl_t = [0.5, 1.0, 2.0, 4.0]\n",
    "abl_hvp_mode = [\"Hv_norm2\", \"vHv\"]\n",
    "abl_sigma = [0.05, 0.1, 0.2]\n",
    "abl_hidden = [\n",
    "    [256, 256, 256, 256],\n",
    "    [512, 512],\n",
    "    [512, 512, 512, 512, 512, 512],\n",
    "]\n",
    "abl_lr = [5e-4, 1e-3, 2e-3]\n",
    "abl_batch_size = [1024, 4096]\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Helper to run one config and append to results\n",
    "def run_single_eggfm_ablation(\n",
    "    adata: sc.AnnData,\n",
    "    params: dict,\n",
    "    labels: np.ndarray,\n",
    "    n_clusters: int,\n",
    "    ari_k: int,\n",
    "    tag: str,\n",
    "    meta: dict,\n",
    "):\n",
    "    # Copy AnnData so we don't accumulate neighbors/umaps/etc\n",
    "    ad = adata.copy()\n",
    "    ad, emb_dict = compute_manifolds(\n",
    "        ad,\n",
    "        params,\n",
    "        n_pcs=ari_k,\n",
    "        seed=params.get(\"seed\", 0),\n",
    "        label_key=None,  # no plotting here\n",
    "        n_neighbors=params[\"eggfm_diffmap\"][\"n_neighbors\"],\n",
    "        methods=[\"diffmap_eggfm\"],  # only EGGFM\n",
    "    )\n",
    "\n",
    "    if \"diffmap_eggfm\" not in emb_dict:\n",
    "        print(f\"[ablation] no diffmap_eggfm produced for tag={tag}, skipping\")\n",
    "        return\n",
    "\n",
    "    emb_name = f\"eggfm_{tag}\"\n",
    "    df = evaluate_embeddings(\n",
    "        embeddings={emb_name: emb_dict[\"diffmap_eggfm\"]},\n",
    "        labels=labels,\n",
    "        n_clusters=n_clusters,\n",
    "        n_seeds=10,\n",
    "        seed=0,\n",
    "        ari_k=ari_k,\n",
    "        plot=False,\n",
    "    )\n",
    "    # attach metadata columns\n",
    "    for k, v in meta.items():\n",
    "        df[k] = v\n",
    "    df[\"tag\"] = tag\n",
    "    results.append(df)\n",
    "\n",
    "\n",
    "ari_k = base_params[\"spec\"][\"ari_n_dims\"]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) n_neighbors ablation\n",
    "# -------------------------------------------------------------------\n",
    "for nn in abl_n_neighbors:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_diffmap\"][\"n_neighbors\"] = nn\n",
    "    tag = f\"nnb{nn}\"\n",
    "    meta = {\"group\": \"n_neighbors\", \"n_neighbors\": nn}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) diffusion time t\n",
    "# -------------------------------------------------------------------\n",
    "for t in abl_t:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_diffmap\"][\"t\"] = t\n",
    "    tag = f\"t{t}\"\n",
    "    meta = {\"group\": \"t\", \"t\": t}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) hvp_mode: Hv_norm2 vs vHv\n",
    "# -------------------------------------------------------------------\n",
    "for mode in abl_hvp_mode:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_diffmap\"][\"hvp_mode\"] = mode\n",
    "    tag = f\"hvp_{mode}\"\n",
    "    meta = {\"group\": \"hvp_mode\", \"hvp_mode\": mode}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) sigma in DSM\n",
    "# -------------------------------------------------------------------\n",
    "for sigma in abl_sigma:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_train\"][\"sigma\"] = sigma\n",
    "    tag = f\"sigma{sigma}\"\n",
    "    meta = {\"group\": \"sigma\", \"sigma\": sigma}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) hidden_dims capacity\n",
    "# -------------------------------------------------------------------\n",
    "for hd in abl_hidden:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_model\"][\"hidden_dims\"] = hd\n",
    "    tag = \"hd_\" + \"x\".join(str(h) for h in hd)\n",
    "    meta = {\"group\": \"hidden_dims\", \"hidden_dims\": str(hd)}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6) learning rate\n",
    "# -------------------------------------------------------------------\n",
    "for lr in abl_lr:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_train\"][\"lr\"] = lr\n",
    "    tag = f\"lr{lr}\"\n",
    "    meta = {\"group\": \"lr\", \"lr\": lr}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7) batch size\n",
    "# -------------------------------------------------------------------\n",
    "for bs in abl_batch_size:\n",
    "    params = copy.deepcopy(base_params)\n",
    "    params[\"eggfm_train\"][\"batch_size\"] = bs\n",
    "    tag = f\"bs{bs}\"\n",
    "    meta = {\"group\": \"batch_size\", \"batch_size\": bs}\n",
    "    run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Combine & save\n",
    "# -------------------------------------------------------------------\n",
    "if results:\n",
    "    all_results = pd.concat(results, ignore_index=True)\n",
    "    all_results.to_csv(\"out/eggfm_ablation_results.csv\", index=False)\n",
    "    print(all_results.head())\n",
    "else:\n",
    "    print(\"No ablation results collected.\")\n",
    "    \n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d71800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARI] dcol_pca       : mean=0.2422, std=0.0055\n",
      "[ARI] pca            : mean=0.3088, std=0.0058\n",
      "[ARI] diffmap_pca    : mean=0.3045, std=0.0024\n",
      "[ARI] diffmap_dcol   : mean=0.2606, std=0.0024\n",
      "[ARI] diffmap_eggfm  : mean=0.2355, std=0.0067\n",
      "[ARI] phate          : mean=0.2921, std=0.0052\n",
      "[ARI] scvi           : mean=0.3083, std=0.0091\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b0de3125-b01b-44ef-9bbc-08a138f0cfd5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean_ari</th>\n",
       "      <th>std_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.005817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scvi</td>\n",
       "      <td>0.308336</td>\n",
       "      <td>0.009149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diffmap_pca</td>\n",
       "      <td>0.304482</td>\n",
       "      <td>0.002416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phate</td>\n",
       "      <td>0.292067</td>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diffmap_dcol</td>\n",
       "      <td>0.260639</td>\n",
       "      <td>0.002420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dcol_pca</td>\n",
       "      <td>0.242163</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diffmap_eggfm</td>\n",
       "      <td>0.235543</td>\n",
       "      <td>0.006665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0de3125-b01b-44ef-9bbc-08a138f0cfd5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b0de3125-b01b-44ef-9bbc-08a138f0cfd5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b0de3125-b01b-44ef-9bbc-08a138f0cfd5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          method  mean_ari   std_ari\n",
       "0            pca  0.308780  0.005817\n",
       "1           scvi  0.308336  0.009149\n",
       "2    diffmap_pca  0.304482  0.002416\n",
       "3          phate  0.292067  0.005177\n",
       "4   diffmap_dcol  0.260639  0.002420\n",
       "5       dcol_pca  0.242163  0.005500\n",
       "6  diffmap_eggfm  0.235543  0.006665"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adata_paul15, paul15_embeddings, paul15_df = run_paul15_manifold_panel(\n",
    "#     out=\"out/paul15_dimred_summary.csv\",\n",
    "#     n_top_genes=2000,\n",
    "#     n_pcs=50,\n",
    "#     seed=0,\n",
    "#     n_seeds=10,\n",
    "# )\n",
    "\n",
    "# Example for Paul15\n",
    "labels_cat = adata.obs[\"paul15_clusters\"].astype(\"category\")\n",
    "labels = labels_cat.cat.codes.to_numpy()\n",
    "n_clusters = labels_cat.cat.categories.size\n",
    "\n",
    "df_ari = evaluate_embeddings(\n",
    "    embeddings,\n",
    "    labels=labels,\n",
    "    n_clusters=n_clusters,\n",
    "    n_seeds=10,\n",
    "    seed=0,\n",
    "    ari_k=10,\n",
    "    plot=True,\n",
    ")\n",
    "df_ari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
