{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fca7d56",
   "metadata": {},
   "source": [
    "# Preprocess paul15 scRNA-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30f8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.9/628.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.4/259.4 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Core scientific stack\n",
    "%pip install --quiet numpy scipy pandas matplotlib scikit-learn\n",
    "\n",
    "# Scanpy for single-cell analysis\n",
    "%pip install --quiet scanpy\n",
    "\n",
    "# PHATE for manifold learning\n",
    "%pip install --quiet phate\n",
    "\n",
    "# scVI for latent representations\n",
    "%pip install --quiet scvi-tools\n",
    "\n",
    "# (Optional, but often useful)\n",
    "%pip install --quiet umap-learn \n",
    "%pip install --quiet ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad3da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75cc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_energy.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import sparse\n",
    "import scanpy as sc  # only for type hints; not strictly necessary\n",
    "\n",
    "\n",
    "class AnnDataExpressionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps an AnnData object's X matrix (after prep()) as a PyTorch dataset.\n",
    "    Uses HVG, log-normalized expression directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ad: \"sc.AnnData\", float_dtype: np.dtype = np.float32):\n",
    "        X = ad.X\n",
    "        if sparse.issparse(X):\n",
    "            X = X.toarray()\n",
    "        X = np.asarray(X, dtype=float_dtype)\n",
    "        # Optional: mean-center features for numerical stability\n",
    "        self.mean_ = X.mean(axis=0, keepdims=True)\n",
    "        self.X = X - self.mean_\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31a2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffmap_eggfm.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def hessian_quadratic_form_batched(\n",
    "    energy_model,\n",
    "    X_batch: np.ndarray,  # (B, D) points x_b\n",
    "    V_batch: np.ndarray,  # (B, D) directions v_b\n",
    "    device: str,\n",
    "    mode: str = \"Hv_norm2\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Batched Hessian-based quadratic form q_{x_b}(v_b) for b=1..B using HVPs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    energy_model : nn.Module\n",
    "        Trained energy model: E(x) = <E_theta(x), x>.\n",
    "    X_batch : (B, D) np.ndarray\n",
    "        Batch of points x_b at which to evaluate the metric.\n",
    "    V_batch : (B, D) np.ndarray\n",
    "        Batch of directions v_b (e.g. displacements to neighbors).\n",
    "    device : str\n",
    "        \"cuda\" or \"cpu\". Assumes energy_model is already on this device.\n",
    "    mode : {\"Hv_norm2\", \"vHv\"}\n",
    "        - \"Hv_norm2\": q_b = ||H_E(x_b) v_b||^2  (>= 0, SPD-like).\n",
    "        - \"vHv\":      q_b = v_b^T H_E(x_b) v_b  (can be indefinite).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    q_batch : (B,) np.ndarray\n",
    "        Quadratic form values q_{x_b}(v_b) per pair.\n",
    "    \"\"\"\n",
    "    # Move data to device\n",
    "    x = torch.from_numpy(X_batch).to(device=device, dtype=torch.float32)\n",
    "    v = torch.from_numpy(V_batch).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    # We want per-sample Hessian-vector products, so keep x as a batch with grad\n",
    "    x = x.requires_grad_(True)\n",
    "\n",
    "    # 1) First gradient: g_b = ∇_x E(x_b) for each b\n",
    "    E: Tensor = energy_model(x).sum()  # sum over batch -> scalar\n",
    "    (g,) = torch.autograd.grad(\n",
    "        E,\n",
    "        x,\n",
    "        create_graph=True,  # we need graph for second derivative\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )  # g shape: (B, D)\n",
    "\n",
    "    # 2) For each b, gv_b = g_b · v_b; then sum over b to get scalar\n",
    "    gv = (g * v).sum(dim=1)  # (B,)\n",
    "    gv_sum = gv.sum()\n",
    "\n",
    "    # 3) Second gradient: Hv_b = ∇_x gv_b (batched via gv_sum)\n",
    "    (Hv,) = torch.autograd.grad(\n",
    "        gv_sum,\n",
    "        x,\n",
    "        create_graph=False,\n",
    "        retain_graph=False,\n",
    "        only_inputs=True,\n",
    "    )  # Hv shape: (B, D)\n",
    "\n",
    "    if mode == \"Hv_norm2\":\n",
    "        q_batch = (Hv * Hv).sum(dim=1)  # ||H v||^2 per sample\n",
    "    elif mode == \"vHv\":\n",
    "        q_batch = (v * Hv).sum(dim=1)  # v^T H v per sample\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode for hessian_quadratic_form_batched: {mode}\")\n",
    "\n",
    "    q_batch = q_batch.detach().cpu().numpy()\n",
    "    q_batch[q_batch < 1e-12] = 1e-12\n",
    "    return q_batch\n",
    "\n",
    "\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def build_eggfm_diffmap(\n",
    "    ad_prep,\n",
    "    energy_model,\n",
    "    diff_cfg: Dict[str, Any],\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an EGGFM-aware Diffusion Map embedding using a metric induced by\n",
    "    the Hessian of the energy model via batched Hessian-vector products.\n",
    "    \"\"\"\n",
    "    X = ad_prep.X\n",
    "    if sp_sparse.issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    n_cells, D = X.shape\n",
    "\n",
    "    n_neighbors = diff_cfg.get(\"n_neighbors\", 30)\n",
    "    n_comps = diff_cfg.get(\"n_comps\", 30)\n",
    "    device = diff_cfg.get(\"device\", \"cuda\")\n",
    "    device = device if torch.cuda.is_available() else \"cpu\"\n",
    "    eps_mode = diff_cfg.get(\"eps_mode\", \"median\")\n",
    "    eps_value = float(diff_cfg.get(\"eps_value\", 1.0))\n",
    "    hvp_mode = diff_cfg.get(\"hvp_mode\", \"Hv_norm2\")\n",
    "    hvp_batch_size = diff_cfg.get(\"hvp_batch_size\", 1024)\n",
    "    t = diff_cfg.get(\"t\", 1.0)\n",
    "\n",
    "    # Move model to device once\n",
    "    energy_model = energy_model.to(device)\n",
    "    energy_model.eval()\n",
    "\n",
    "    print(f\"[EGGFM DiffMap] X shape: {X.shape}\", flush=True)\n",
    "\n",
    "    # 1) kNN for neighbor selection (Euclidean, only for neighbor indices)\n",
    "    print(\n",
    "        \"[EGGFM DiffMap] building kNN graph (euclidean for neighbor selection)...\",\n",
    "        flush=True,\n",
    "    )\n",
    "    nn_abln = NearestNeighbors(n_neighbors=n_neighbors + 1, metric=\"euclidean\")\n",
    "    nn_abln.fit(X)\n",
    "    distances, indices = nn_abln.kneighbors(X)\n",
    "\n",
    "    # neighbors per cell (excluding self)\n",
    "    k = indices.shape[1] - 1\n",
    "    assert k == n_neighbors, \"indices second dimension should be n_neighbors+1\"\n",
    "\n",
    "    # 2) Flatten edges\n",
    "    rows = np.repeat(np.arange(n_cells, dtype=np.int64), k)\n",
    "    cols = indices[:, 1:].reshape(-1).astype(np.int64)\n",
    "    n_edges = rows.shape[0]\n",
    "\n",
    "    print(f\"[EGGFM DiffMap] total edges (directed): {n_edges}\", flush=True)\n",
    "\n",
    "    # 3) Compute metric-aware edge lengths ℓ_ij^2 via batched HVPs\n",
    "    l2_vals = np.empty(n_edges, dtype=np.float64)\n",
    "\n",
    "    print(\n",
    "        \"[EGGFM DiffMap] computing Hessian-based edge lengths in batches...\", flush=True\n",
    "    )\n",
    "    n_batches = (n_edges + hvp_batch_size - 1) // hvp_batch_size\n",
    "\n",
    "    for b in range(n_batches):\n",
    "        start = b * hvp_batch_size\n",
    "        end = min((b + 1) * hvp_batch_size, n_edges)\n",
    "        if start >= end:\n",
    "            break\n",
    "\n",
    "        i_batch = rows[start:end]\n",
    "        j_batch = cols[start:end]\n",
    "\n",
    "        Xi_batch = X[i_batch]  # (B, D)\n",
    "        Xj_batch = X[j_batch]  # (B, D)\n",
    "        V_batch = Xj_batch - Xi_batch  # (B, D)\n",
    "\n",
    "        q_batch = hessian_quadratic_form_batched(\n",
    "            energy_model,\n",
    "            Xi_batch,\n",
    "            V_batch,\n",
    "            device=device,\n",
    "            mode=hvp_mode,\n",
    "        )\n",
    "        l2_vals[start:end] = q_batch\n",
    "\n",
    "        if (b + 1) % 50 == 0 or b == n_batches - 1:\n",
    "            print(\n",
    "                f\"  processed batch {b+1}/{n_batches} ({end} / {n_edges} edges)\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3.5) Robust cleaning + clipping of l2_vals\n",
    "    # ----------------------------------------------------\n",
    "    # keep only finite, positive values for scale estimation\n",
    "    finite_pos = np.isfinite(l2_vals) & (l2_vals > 0)\n",
    "    if not finite_pos.any():\n",
    "        print(\n",
    "            \"[EGGFM DiffMap] WARNING: no positive finite l2_vals; \"\n",
    "            f\"falling back to eps_value={eps_value}\"\n",
    "        )\n",
    "        # fill NaNs / non-positive with 1.0 so kernel isn't degenerate\n",
    "        l2_vals = np.nan_to_num(l2_vals, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "        q_low = 0.0\n",
    "        q_hi = 1.0\n",
    "        eps = eps_value\n",
    "    else:\n",
    "        l2_clean = l2_vals[finite_pos]\n",
    "        q_low = np.quantile(l2_clean, 0.05)\n",
    "        q_hi = np.quantile(l2_clean, 0.98)\n",
    "        # clip all edges to [q_low, q_hi]\n",
    "        l2_vals = np.clip(l2_vals, q_low, q_hi)\n",
    "        # replace any remaining non-finite entries with median of the clean set\n",
    "        median_clean = float(np.median(l2_clean))\n",
    "        bad = ~np.isfinite(l2_vals)\n",
    "        if bad.any():\n",
    "            l2_vals[bad] = median_clean\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        # 4) Choose kernel bandwidth ε (guarded)\n",
    "        # ------------------------------------------------\n",
    "        if eps_mode == \"median\":\n",
    "            eps = float(np.median(l2_vals[finite_pos]))\n",
    "        elif eps_mode == \"fixed\":\n",
    "            eps = eps_value\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown eps_mode: {eps_mode}\")\n",
    "\n",
    "    # final safety: ensure eps is finite and > 0\n",
    "    if not np.isfinite(eps) or eps <= 0:\n",
    "        print(\n",
    "            f\"[EGGFM DiffMap] WARNING: bad eps={eps}; \"\n",
    "            f\"falling back to eps_value={eps_value}\"\n",
    "        )\n",
    "        eps = eps_value\n",
    "\n",
    "    print(\n",
    "        f\"[EGGFM DiffMap] q_low={q_low:.4g}, q_hi={q_hi:.4g}, eps={eps:.4g}\", flush=True\n",
    "    )\n",
    "\n",
    "    # 5) Build kernel W_ij = exp(-ℓ_ij^2 / eps)\n",
    "    W_vals = np.exp(-l2_vals / eps)\n",
    "    # guard against NaNs/Infs in W_vals\n",
    "    W_vals = np.nan_to_num(W_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    W = sparse.csr_matrix((W_vals, (rows, cols)), shape=(n_cells, n_cells))\n",
    "    # Symmetrize for robustness\n",
    "    W = 0.5 * (W + W.T)\n",
    "\n",
    "    # 6) Normalize to Markov matrix P (row-stochastic)\n",
    "    d = np.array(W.sum(axis=1)).ravel()\n",
    "    d_safe = np.maximum(d, 1e-12)\n",
    "    D_inv = sparse.diags(1.0 / d_safe)\n",
    "    P = D_inv @ W\n",
    "\n",
    "    # 7) Eigendecompose P^T for diffusion map\n",
    "    k_eigs = n_comps + 1  # include trivial eigenpair\n",
    "    print(\"[EGGFM DiffMap] computing eigenvectors...\", flush=True)\n",
    "    eigvals, eigvecs = eigs(P.T, k=k_eigs, which=\"LR\")  # largest real parts\n",
    "\n",
    "    eigvals = eigvals.real\n",
    "    eigvecs = eigvecs.real\n",
    "\n",
    "    # sort by eigenvalue magnitude descending\n",
    "    order = np.argsort(-eigvals)\n",
    "    eigvals = eigvals[order]\n",
    "    eigvecs = eigvecs[:, order]\n",
    "\n",
    "    # drop trivial eigenvector (λ≈1)\n",
    "    lambdas = eigvals[1 : n_comps + 1]\n",
    "    phis = eigvecs[:, 1 : n_comps + 1]  # (n_cells, n_comps)\n",
    "\n",
    "    # Diffusion map coordinates Ψ_t(x_i) = (λ_1^t φ_1(i), ..., λ_m^t φ_m(i))\n",
    "    diff_coords = phis * (lambdas**t)\n",
    "\n",
    "    print(\"[EGGFM DiffMap] finished. Embedding shape:\", diff_coords.shape, flush=True)\n",
    "    return diff_coords.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ef47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_model.py\n",
    "\n",
    "from typing import Sequence, Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class EnergyMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    E(x) = <E_theta(x), x> where E_theta is an MLP with nonlinearities.\n",
    "\n",
    "    x is HVG, log-normalized expression (optionally mean-centered).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_genes: int,\n",
    "        hidden_dims: Sequence[int] = (512, 512, 512, 512),\n",
    "        activation: Optional[nn.Module] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if activation is None:\n",
    "            activation = nn.Softplus()\n",
    "\n",
    "        layers = []\n",
    "        in_dim = n_genes\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(activation)\n",
    "            in_dim = h\n",
    "        # final layer outputs a vector in R^D\n",
    "        layers.append(nn.Linear(in_dim, n_genes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, D)\n",
    "        returns: energy (B,)\n",
    "        \"\"\"\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        v = self.net(x)  # (B, D) = E_theta(x)\n",
    "        energy = (v * x).sum(dim=-1)  # <E_theta(x), x>\n",
    "        return energy\n",
    "\n",
    "    def score(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        score(x) ≈ ∇_x log p(x) = -∇_x E(x)\n",
    "        \"\"\"\n",
    "        x = x.clone().detach().requires_grad_(True)\n",
    "        energy = self.forward(x)  # (B,)\n",
    "        energy_sum = energy.sum()\n",
    "        (grad,) = torch.autograd.grad(\n",
    "            energy_sum,\n",
    "            x,\n",
    "            create_graph=False,\n",
    "            retain_graph=False,\n",
    "            only_inputs=True,\n",
    "        )\n",
    "        score = -grad\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_energy.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_energy_model(\n",
    "    ad_prep,  # output of prep(ad, params)\n",
    "    model_cfg: Dict[str, Any],\n",
    "    train_cfg: Dict[str, Any],\n",
    ") -> EnergyMLP:\n",
    "    \"\"\"\n",
    "    Train an energy-based model on preprocessed AnnData using denoising score matching.\n",
    "\n",
    "    model_cfg (from params['eggfm_model']), e.g.:\n",
    "        hidden_dims: [512, 512, 512, 512]\n",
    "\n",
    "    train_cfg (from params['eggfm_train']), e.g.:\n",
    "        batch_size: 2048\n",
    "        num_epochs: 50\n",
    "        lr: 1e-4\n",
    "        sigma: 0.1\n",
    "        device: \"cuda\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Device\n",
    "    device = train_cfg.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset\n",
    "    dataset = AnnDataExpressionDataset(ad_prep)\n",
    "    n_genes = dataset.X.shape[1]\n",
    "\n",
    "    # Model\n",
    "    hidden_dims = model_cfg.get(\"hidden_dims\", (512, 512, 512, 512))\n",
    "    model = EnergyMLP(\n",
    "        n_genes=n_genes,\n",
    "        hidden_dims=hidden_dims,\n",
    "    ).to(device)\n",
    "\n",
    "    # Training hyperparameters (YAML overrides defaults)\n",
    "    batch_size = int(train_cfg.get(\"batch_size\", 2048))\n",
    "    num_epochs = int(train_cfg.get(\"num_epochs\", 50))\n",
    "    lr = float(train_cfg.get(\"lr\", 1e-4))\n",
    "    sigma = float(train_cfg.get(\"sigma\", 0.1))\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in loader:\n",
    "            x = batch.to(device)  # (B, D)\n",
    "            # Sample Gaussian noise\n",
    "            eps = torch.randn_like(x)\n",
    "            y = x + sigma * eps\n",
    "            y.requires_grad_(True)\n",
    "\n",
    "            # Predicted score at y: s_theta(y) = -∇_y E(y)\n",
    "            energy = model(y)  # (B,)\n",
    "            energy_sum = energy.sum()\n",
    "            (grad_y,) = torch.autograd.grad(\n",
    "                energy_sum,\n",
    "                y,\n",
    "                create_graph=False,\n",
    "                retain_graph=False,\n",
    "                only_inputs=True,\n",
    "            )\n",
    "            s_theta = -grad_y  # (B, D)\n",
    "\n",
    "            # DSM target: -(y - x) / sigma^2\n",
    "            target = -(y - x) / (sigma**2)\n",
    "\n",
    "            # MSE over batch and dimensions\n",
    "            loss = ((s_theta - target) ** 2).sum(dim=1).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        print(\n",
    "            f\"[Energy DSM] Epoch {epoch+1}/{num_epochs}  loss={epoch_loss:.4f}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eggfm_dimred(\n",
    "    qc_ad: sc.AnnData,\n",
    "    params: Dict[str, Any],\n",
    ") -> Tuple[sc.AnnData, object]:\n",
    "    \"\"\"\n",
    "    Run EGGFM-based dimension reduction on a preprocessed AnnData.\n",
    "\n",
    "    Assumes qc_ad is already:\n",
    "      - gene-filtered\n",
    "      - HVG-selected\n",
    "      - normalized + log1p\n",
    "\n",
    "    Config sections (from params.yml):\n",
    "      eggfm_model:\n",
    "        hidden_dims: [512, 512, 512, 512]\n",
    "\n",
    "      eggfm_train:\n",
    "        batch_size: 2048\n",
    "        num_epochs: 50\n",
    "        lr: 1e-4\n",
    "        sigma: 0.1\n",
    "        device: \"cuda\"\n",
    "\n",
    "      eggfm_diffmap:\n",
    "        n_neighbors: 10\n",
    "        n_comps: 30\n",
    "        device: \"cuda\"\n",
    "        hvp_mode: \"vHv\"\n",
    "        hvp_batch_size: 2048\n",
    "        eps_mode: \"median\"\n",
    "        eps_value: 1.0\n",
    "        t: 1.0\n",
    "    \"\"\"\n",
    "\n",
    "    # Let the train/diffmap functions handle their own defaults.\n",
    "    model_cfg = params.get(\"eggfm_model\", {})\n",
    "    train_cfg = params.get(\"eggfm_train\", {})\n",
    "    diff_cfg = params.get(\"eggfm_diffmap\", {})\n",
    "\n",
    "    # 1) Train energy model\n",
    "    energy_model = train_energy_model(qc_ad, model_cfg, train_cfg)\n",
    "\n",
    "    # 2) Build EGGFM DiffMap embedding (no subsampling)\n",
    "    X_eggfm = build_eggfm_diffmap(qc_ad, energy_model, diff_cfg)\n",
    "    qc_ad.obsm[\"X_diff_eggfm\"] = X_eggfm  # make sure clustering sees this\n",
    "    qc_ad.uns[\"eggfm_meta\"] = {\n",
    "        \"hidden_dims\": model_cfg.get(\"hidden_dims\"),\n",
    "        \"batch_size\": train_cfg.get(\"batch_size\"),\n",
    "        \"lr\": train_cfg.get(\"lr\"),\n",
    "        \"sigma\": train_cfg.get(\"sigma\"),\n",
    "        \"n_neighbors\": diff_cfg.get(\"n_neighbors\"),\n",
    "        \"hvp_mode\": diff_cfg.get(\"hvp_mode\"),\n",
    "    }\n",
    "    return qc_ad, energy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643cef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def prep_for_manifolds(\n",
    "    ad: sc.AnnData,\n",
    "    min_genes: int = 200,\n",
    "    hvg_n_top_genes: int = 2000,\n",
    "    min_cells_frac: float = 0.001,\n",
    ") -> sc.AnnData:\n",
    "    \"\"\"\n",
    "    Preprocessing that mirrors your real `prep` function:\n",
    "\n",
    "      - QC metrics\n",
    "      - filter genes by min_cells_frac * n_cells\n",
    "      - filter cells by min_genes\n",
    "      - drop zero-total cells\n",
    "      - HVG selection (Seurat v3, subset=False)\n",
    "      - subset to HVGs\n",
    "      - normalize_total + log1p\n",
    "\n",
    "    No PCA here; we keep the data nonlinear for downstream DR.\n",
    "    \"\"\"\n",
    "    n_cells = ad.n_obs\n",
    "    print(\"[prep_for_manifolds] running Scanpy QC metrics\", flush=True)\n",
    "    sc.pp.calculate_qc_metrics(ad, inplace=True)\n",
    "\n",
    "    # Remove genes that are not statistically relevant (< min_cells_frac of cells)\n",
    "    min_cells = max(3, int(min_cells_frac * n_cells))\n",
    "    sc.pp.filter_genes(ad, min_cells=min_cells)\n",
    "\n",
    "    # Remove empty droplets / low-complexity cells\n",
    "    sc.pp.filter_cells(ad, min_genes=min_genes)\n",
    "\n",
    "    # Drop zero-count cells\n",
    "    totals = np.ravel(ad.X.sum(axis=1))\n",
    "    ad = ad[totals > 0, :].copy()\n",
    "\n",
    "    print(\"n_obs, n_vars (pre-HVG):\", ad.n_obs, ad.n_vars, flush=True)\n",
    "\n",
    "    # Explicit mean check, like in your script\n",
    "    X = ad.X\n",
    "    if sparse.issparse(X):\n",
    "        means = np.asarray(X.mean(axis=0)).ravel()\n",
    "    else:\n",
    "        means = np.nanmean(X, axis=0)\n",
    "\n",
    "    print(\"Means finite?\", np.all(np.isfinite(means)), flush=True)\n",
    "    print(\"Means min/max:\", np.nanmin(means), np.nanmax(means), flush=True)\n",
    "    print(\"# non-finite means:\", np.sum(~np.isfinite(means)), flush=True)\n",
    "\n",
    "    # HVG selection on raw X (no raw layer here)\n",
    "    sc.pp.highly_variable_genes(\n",
    "        ad,\n",
    "        n_top_genes=int(hvg_n_top_genes),\n",
    "        flavor=\"seurat_v3\",\n",
    "        subset=False,\n",
    "    )\n",
    "\n",
    "    ad = ad[:, ad.var[\"highly_variable\"]].copy()\n",
    "    print(\"n_obs, n_vars (post-HVG):\", ad.n_obs, ad.n_vars, flush=True)\n",
    "\n",
    "    # Now normalize/log on X\n",
    "    sc.pp.normalize_total(ad, target_sum=1e4)\n",
    "    sc.pp.log1p(ad)\n",
    "\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cb4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "# Optional plotting / clustering helpers (for plot_result)\n",
    "# Comment these out if you don't need them.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _standardize(X: np.ndarray, axis: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Center and scale X along the given axis (like R's scale()).\n",
    "    axis=0 => column-wise standardization.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    mean = X.mean(axis=axis, keepdims=True)\n",
    "    std = X.std(axis=axis, ddof=1, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "###########################################################\n",
    "##### Utilities used in both DCOL-PCA & DCOL-CCA ##########\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def scol_matrix_order(a: np.ndarray, x: np.ndarray) -> np.ndarray | float:\n",
    "    \"\"\"\n",
    "    Python version of scol.matrix.order(a, x).\n",
    "\n",
    "    x: 1D array used to order samples.\n",
    "    a: either a vector of length n_samples or a matrix with shape (n_rows, n_samples).\n",
    "       Returns:\n",
    "         - scalar if a is a vector / single-row\n",
    "         - 1D array of length n_rows if a is 2D (row-wise DCOL distances).\n",
    "    \"\"\"\n",
    "    a = np.asarray(a)\n",
    "    x = np.asarray(x)\n",
    "    order = np.argsort(x)\n",
    "\n",
    "    # a is effectively a vector (R's \"is.null(nrow(a)) | nrow(a) == 1\")\n",
    "    if a.ndim == 1 or a.shape[0] == 1:\n",
    "        a_vec = a.ravel()[order]\n",
    "        d = np.diff(a_vec)\n",
    "        dd = np.sum(d**2)\n",
    "        return float(dd)\n",
    "\n",
    "    # otherwise: matrix case, rows = features, cols = samples\n",
    "    a_sorted = a[:, order]\n",
    "    d = np.diff(a_sorted, axis=1)\n",
    "    dd = np.sum(d**2, axis=1)  # rowSums\n",
    "    return dd\n",
    "\n",
    "\n",
    "def find_dcol(a: np.ndarray, b: np.ndarray, n_nodes: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Python version of findDCOL(a, b, nNodes).\n",
    "\n",
    "    a, b: 2D arrays with shape (n_rows, n_samples).\n",
    "          Rows are features, columns are samples.\n",
    "    n_nodes: kept for API parity; current implementation is sequential.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dcol : np.ndarray, shape (nrow(a), nrow(b))\n",
    "        Symmetric DCOL distance matrix when a and b refer to the same set.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "\n",
    "    # vector vs vector case\n",
    "    if a.ndim == 1 or a.shape[0] == 1:\n",
    "        # a, b are treated as vectors\n",
    "        return np.array(scol_matrix_order(a, b), ndmin=1)\n",
    "\n",
    "    n_a = a.shape[0]\n",
    "    n_b = b.shape[0]\n",
    "\n",
    "    # NOTE: for simplicity, this is sequential. You can parallelize these loops\n",
    "    # with multiprocessing / joblib if needed.\n",
    "    dcolab = np.zeros((n_a, n_b), dtype=float)\n",
    "    dcolba = np.zeros((n_a, n_b), dtype=float)\n",
    "\n",
    "    # dcolab[i_column] = scol_matrix_order(a, b[i, ])\n",
    "    for i in range(n_b):\n",
    "        dcolab[:, i] = scol_matrix_order(a, b[i, :])\n",
    "\n",
    "    # dcolba[j_row] = scol_matrix_order(b, a[j, ])\n",
    "    for j in range(n_a):\n",
    "        dcolba[j, :] = scol_matrix_order(b, a[j, :])\n",
    "\n",
    "    # retain the smaller entry to enforce symmetry\n",
    "    dcol = np.minimum(dcolab, dcolba)\n",
    "    return dcol\n",
    "\n",
    "\n",
    "def get_cov(\n",
    "    dcol_matrix: np.ndarray, X: np.ndarray, Y: np.ndarray\n",
    ") -> np.ndarray | float:\n",
    "    \"\"\"\n",
    "    Python version of getCov(DCOLMatrix, X, Y).\n",
    "\n",
    "    X, Y: data matrices with shape (n_samples, n_features), rows = samples.\n",
    "    dcol_matrix:\n",
    "      - scalar / length-1 => vector case (single pair).\n",
    "      - 2D matrix (p x p) => DCOL distances between features (columns of Y).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - scalar in the vector case\n",
    "    - CovMatrix (DCOL-correlation matrix), same shape as dcol_matrix in matrix case.\n",
    "    \"\"\"\n",
    "    dcol = np.asarray(dcol_matrix, float)\n",
    "    X = np.asarray(X, float)\n",
    "    Y = np.asarray(Y, float)\n",
    "\n",
    "    # Vector / scalar case\n",
    "    if dcol.ndim == 0 or (dcol.ndim == 1 and dcol.shape[0] == 1):\n",
    "        X = X.ravel()\n",
    "        Y = Y.ravel()\n",
    "        n = X.shape[0]\n",
    "        var_Y = np.var(Y, ddof=1)\n",
    "        if var_Y <= 0:\n",
    "            # Degenerate case: no variance in Y, return 0 correlation\n",
    "            return 0.0\n",
    "        value = np.sqrt(max(0.0, 1.0 - dcol.item() / (2.0 * (n - 2.0) * var_Y)))\n",
    "        return float(value)\n",
    "\n",
    "    # Matrix case\n",
    "    n = X.shape[0]\n",
    "    var_list = np.var(Y, axis=0, ddof=1)  # sample variance over samples\n",
    "\n",
    "    eps = 1e-12\n",
    "    zero_var = var_list <= eps\n",
    "    if np.any(zero_var):\n",
    "        print(\n",
    "            f\"[get_cov] {zero_var.sum()} zero-variance features; stabilizing\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "    scale = np.zeros_like(var_list)\n",
    "    ok = ~zero_var\n",
    "    scale[ok] = 1.0 / (2.0 * (n - 2.0) * var_list[ok])\n",
    "\n",
    "    # eigenMapMatMult(DCOLMatrix, diag(scale)) == column-wise scaling by 'scale'\n",
    "    cov_matrix = 1.0 - dcol * scale  # broadcast scale across rows\n",
    "    cov_matrix[cov_matrix < 0] = 0.0  # clamp negs to 0 for num stability\n",
    "\n",
    "    # For zero-var features, zero out row/cl and set diag to 1\n",
    "    if np.any(zero_var):\n",
    "        cov_matrix[:, zero_var] = 0.0\n",
    "        cov_matrix[zero_var, :] = 0.0\n",
    "        idx = np.where(zero_var)[0]\n",
    "        cov_matrix[idx, idx] = 1.0\n",
    "\n",
    "    cov_matrix = np.sqrt(cov_matrix)\n",
    "    return cov_matrix\n",
    "\n",
    "\n",
    "###########################################################\n",
    "##### DCOL-PCA (feature-based and cell-based versions) ####\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def dcol_pca0(\n",
    "    X: np.ndarray,\n",
    "    k: int = 4,\n",
    "    Scale: bool = True,\n",
    "    nNodes: int = 1,\n",
    "    nPC_max: int = 100,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Python version of Dcol_PCA0(X, ...).\n",
    "    PCA with n = cells and k = principal k features\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Columns are features (genes), rows are samples (cells).    \n",
    "    k : int\n",
    "        Number of dimensions to keep for 'data.r' (visualization).\n",
    "    labels : array-like, optional\n",
    "        Group labels for plotting (unused unless you add plotting).\n",
    "    Scale : bool\n",
    "        Whether to standardize features before computing DCOL.\n",
    "    nNodes : int\n",
    "        Kept for API compatibility; current implementation is sequential.\n",
    "    nPC_max : int\n",
    "        Maximum number of principal components to compute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "      - 'cov_D'      : DCOL-based correlation matrix (p x p)\n",
    "      - 'vecs'   : eigenvectors of cov_D (p x nPC)\n",
    "      - 'vals'    : eigenvalues (nPC,)\n",
    "      - 'data_r'     : embedding (n_samples x min(k, nPC))\n",
    "      - 'X_proj'     : full projection (n_samples x nPC)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    X_o = X.copy()  # used for final projection\n",
    "\n",
    "    if Scale:\n",
    "        X = _standardize(X, axis=0)  # column-wise (features)\n",
    "\n",
    "    # DCOL matrix over features: findDCOL(t(X), t(X))\n",
    "    DcolMatrix = find_dcol(X.T, X.T, n_nodes=nNodes)\n",
    "    cov_D = get_cov(DcolMatrix, X, X)  # DCOL-correlation matrix\n",
    "\n",
    "    # Suppose cov_D is the matrix passed to eigsh\n",
    "    print(\"[dcol_pca] cov_D finite?\", np.isfinite(cov_D).all(), flush=True)\n",
    "    print(\"[dcol_pca] cov_D min/max:\", np.nanmin(cov_D), np.nanmax(cov_D), flush=True)\n",
    "\n",
    "    # Eigen-decomposition (like RSpectra::eigs_sym on symmetric cov_D)\n",
    "    p = cov_D.shape[0]\n",
    "    nPC = min(nPC_max, p)\n",
    "\n",
    "    # Enforce symmetry and remove NaN/Inf just in case\n",
    "    cov_D = 0.5 * (cov_D + cov_D.T)\n",
    "    cov_D = np.nan_to_num(cov_D, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Add tiny diagonal jitter for numerical stablility\n",
    "    cov_D.flat[:: p + 1] += 1e-8\n",
    "\n",
    "    if p <= nPC + 10:\n",
    "        # small matrix: use dense eigh\n",
    "        vals, vecs = np.linalg.eigh(cov_D)\n",
    "        idx = np.argsort(vals)[::-1][:nPC]\n",
    "        vals = vals[idx]\n",
    "        vecs = vecs[:, idx]\n",
    "    else:\n",
    "        # large matrix: sparse eigensolver\n",
    "        vals, vecs = eigsh(cov_D, k=nPC, which=\"LM\")\n",
    "        idx = np.argsort(vals)[::-1]\n",
    "        vals = vals[idx]\n",
    "        vecs = vecs[:, idx]\n",
    "\n",
    "    # Project original (unscaled) X onto eigenvectors\n",
    "    X_proj = X_o @ vecs  # (n_samples x nPC)\n",
    "    data_r = X_proj[:, : min(k, X_proj.shape[1])]\n",
    "\n",
    "    # You can add plotting here if image == 1 (using matplotlib).\n",
    "\n",
    "    return {\n",
    "        \"cov_D\": cov_D,\n",
    "        \"vecs\": vecs,\n",
    "        \"vals\": vals,\n",
    "        \"data_r\": data_r,\n",
    "        \"X_proj\": X_proj,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66eb3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple, Sequence, Optional\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def compute_manifolds(\n",
    "    adata: sc.AnnData,\n",
    "    params: Dict[str, Any],\n",
    "    n_pcs: int = 50,\n",
    "    seed: int = 0,\n",
    "    label_key: str | None = None,\n",
    "    n_neighbors: int = 30,\n",
    "    umap_min_dist: float = 0.3,\n",
    "    methods: Optional[Sequence[str]] = None,\n",
    "    umap_plot:bool = False\n",
    ") -> Tuple[sc.AnnData, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Compute a small panel of embeddings on `adata` and optionally display\n",
    "    a UMAP for each manifold inline (Jupyter style).\n",
    "\n",
    "    methods:\n",
    "        Which embeddings to compute. Possible keys:\n",
    "          - \"dcol_pca\"\n",
    "          - \"pca\"\n",
    "          - \"diffmap_pca\"\n",
    "          - \"diffmap_dcol\"\n",
    "          - \"diffmap_eggfm\"\n",
    "          - \"phate\"\n",
    "          - \"scvi\"\n",
    "        If None, all are computed.\n",
    "\n",
    "    Embeddings stored / returned:\n",
    "      - dcol_pca       -> adata.obsm[\"X_dcolpca\"]\n",
    "      - pca            -> adata.obsm[\"X_pca\"]\n",
    "      - diffmap_pca    -> adata.obsm[\"X_diff_pca\"]\n",
    "      - diffmap_dcol   -> adata.obsm[\"X_diff_dcol\"]\n",
    "      - diffmap_eggfm  -> adata.obsm[\"X_diff_eggfm\"]\n",
    "      - phate          -> adata.obsm[\"X_phate\"]\n",
    "      - scvi           -> adata.obsm[\"X_scvi\"]\n",
    "    \"\"\"\n",
    "    if methods is None:\n",
    "        methods_set = {\n",
    "            \"dcol_pca\",\n",
    "            \"pca\",\n",
    "            \"diffmap_pca\",\n",
    "            \"diffmap_dcol\",\n",
    "            \"diffmap_eggfm\",\n",
    "            \"phate\",\n",
    "            \"scvi\",\n",
    "        }\n",
    "    else:\n",
    "        methods_set = set(methods)\n",
    "\n",
    "    embeddings: Dict[str, np.ndarray] = {}\n",
    "    spec = params.get(\"spec\", {})\n",
    "    dcol_max_cells = int(spec.get(\"dcol_max_cells\", 3000))\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 0) DCOL-PCA (fit on subset, project all cells)\n",
    "    # ----------------------------------------------------\n",
    "    if \"dcol_pca\" in methods_set or \"diffmap_dcol\" in methods_set:\n",
    "        if adata.n_obs > dcol_max_cells:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            idx = np.sort(rng.choice(adata.n_obs, size=dcol_max_cells, replace=False))\n",
    "            ad_dcol = adata[idx, :].copy()\n",
    "            print(\n",
    "                f\"[dcol_pca] subsampled {dcol_max_cells}/{adata.n_obs} cells for DCOL-PCA\",\n",
    "                flush=True,\n",
    "            )\n",
    "        else:\n",
    "            ad_dcol = adata.copy()\n",
    "            print(f\"[dcol_pca] using all {adata.n_obs} cells for DCOL-PCA\", flush=True)\n",
    "\n",
    "        X_sub = ad_dcol.X\n",
    "        if sparse.issparse(X_sub):\n",
    "            X_sub = X_sub.toarray()\n",
    "\n",
    "        K_sub = dcol_pca0(X_sub, nPC_max=n_pcs, Scale=True)\n",
    "        vecs_dcol = K_sub[\"vecs\"]  # (n_genes x n_pcs)\n",
    "\n",
    "        X_full = adata.X\n",
    "        if sparse.issparse(X_full):\n",
    "            X_full = X_full.toarray()\n",
    "        X_proj_full_dcol = X_full @ vecs_dcol\n",
    "        adata.obsm[\"X_dcolpca\"] = X_proj_full_dcol\n",
    "        embeddings[\"dcol_pca\"] = X_proj_full_dcol\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1) PCA (baseline)\n",
    "    # ----------------------------------------------------\n",
    "    if \"pca\" in methods_set or \"diffmap_pca\" in methods_set:\n",
    "        if \"X_pca\" not in adata.obsm_keys():\n",
    "            sc.tl.pca(adata, n_comps=n_pcs, svd_solver=\"arpack\", random_state=seed)\n",
    "        embeddings[\"pca\"] = adata.obsm[\"X_pca\"].copy()\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2) Diffusion maps (PCA prior & DCOL prior)\n",
    "    # ----------------------------------------------------\n",
    "    if \"diffmap_pca\" in methods_set:\n",
    "        sc.pp.neighbors(\n",
    "            adata,\n",
    "            n_neighbors=n_neighbors,\n",
    "            use_rep=\"X_pca\",\n",
    "            random_state=seed,\n",
    "        )\n",
    "        sc.tl.diffmap(adata, n_comps=n_pcs)\n",
    "        X_diff_pca = adata.obsm[\"X_diffmap\"][:, :n_pcs].copy()\n",
    "        adata.obsm[\"X_diff_pca\"] = X_diff_pca\n",
    "        embeddings[\"diffmap_pca\"] = X_diff_pca\n",
    "\n",
    "    if \"diffmap_dcol\" in methods_set:\n",
    "        sc.pp.neighbors(\n",
    "            adata,\n",
    "            n_neighbors=n_neighbors,\n",
    "            use_rep=\"X_dcolpca\",\n",
    "            random_state=seed,\n",
    "        )\n",
    "        sc.tl.diffmap(adata, n_comps=n_pcs)\n",
    "        X_diff_dcol = adata.obsm[\"X_diffmap\"][:, :n_pcs].copy()\n",
    "        adata.obsm[\"X_diff_dcol\"] = X_diff_dcol\n",
    "        embeddings[\"diffmap_dcol\"] = X_diff_dcol\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3) EGGFM Diffmap (for ablations)\n",
    "    # ----------------------------------------------------\n",
    "    if \"diffmap_eggfm\" in methods_set:\n",
    "        adata, _ = run_eggfm_dimred(adata, params)\n",
    "        if \"X_diff_eggfm\" in adata.obsm:\n",
    "            X_diff_eggfm = adata.obsm[\"X_diff_eggfm\"]\n",
    "            if X_diff_eggfm.shape[1] > n_pcs:\n",
    "                X_diff_eggfm = X_diff_eggfm[:, :n_pcs]\n",
    "                adata.obsm[\"X_diff_eggfm\"] = X_diff_eggfm\n",
    "            embeddings[\"diffmap_eggfm\"] = X_diff_eggfm\n",
    "        else:\n",
    "            print(\"[eggfm] X_diff_eggfm not found in adata.obsm; skipping.\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 4) PHATE (optional)\n",
    "    # ----------------------------------------------------\n",
    "    if \"phate\" in methods_set:\n",
    "        try:\n",
    "            import phate\n",
    "\n",
    "            X_ph = adata.X\n",
    "            if sparse.issparse(X_ph):\n",
    "                X_ph = X_ph.toarray()\n",
    "\n",
    "            phate_op = phate.PHATE(\n",
    "                n_components=n_pcs,\n",
    "                n_jobs=-1,\n",
    "                random_state=seed,\n",
    "            )\n",
    "            X_phate = phate_op.fit_transform(X_ph)\n",
    "            adata.obsm[\"X_phate\"] = X_phate\n",
    "            embeddings[\"phate\"] = X_phate\n",
    "        except ImportError:\n",
    "            print(\"[warn] phate not installed; skipping PHATE embedding\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 5) scVI latent space (optional)\n",
    "    # ----------------------------------------------------\n",
    "    if \"scvi\" in methods_set:\n",
    "        try:\n",
    "            import scvi\n",
    "\n",
    "            scvi.model.SCVI.setup_anndata(adata)\n",
    "            scvi_model = scvi.model.SCVI(adata, n_latent=min(10, n_pcs))\n",
    "            scvi_model.train(\n",
    "                max_epochs=200,\n",
    "                check_val_every_n_epoch=10,\n",
    "                plan_kwargs={\"lr\": 1e-3},\n",
    "            )\n",
    "            X_scvi = scvi_model.get_latent_representation()\n",
    "            adata.obsm[\"X_scvi\"] = X_scvi\n",
    "            embeddings[\"scvi\"] = X_scvi\n",
    "        except ImportError:\n",
    "            print(\"[warn] scvi-tools not installed; skipping scVI latent\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 6) UMAPs for each embedding (inline, Jupyter style)\n",
    "    # ----------------------------------------------------\n",
    "    if umap_plot:\n",
    "        if label_key is not None:\n",
    "            methods_umap = {\n",
    "                \"X_pca\": \"PCA\",\n",
    "                \"X_dcolpca\": \"DCOL-PCA\",\n",
    "                \"X_diff_pca\": \"Diffmap (PCA)\",\n",
    "                \"X_diff_dcol\": \"Diffmap (DCOL)\",\n",
    "                \"X_diff_eggfm\": \"Diffmap (EGGFM)\",\n",
    "                \"X_phate\": \"PHATE\",\n",
    "                \"X_scvi\": \"scVI\",\n",
    "            }\n",
    "\n",
    "            for obsm_key, title in methods_umap.items():\n",
    "                # only plot if method was requested and exists\n",
    "                base_name = obsm_key.replace(\"X_\", \"\").lower()\n",
    "                if \"diff_eggfm\" in base_name:\n",
    "                    needed = \"diffmap_eggfm\"\n",
    "                elif \"diff_pca\" in base_name:\n",
    "                    needed = \"diffmap_pca\"\n",
    "                elif \"diff_dcol\" in base_name:\n",
    "                    needed = \"diffmap_dcol\"\n",
    "                elif \"dcolpca\" in base_name:\n",
    "                    needed = \"dcol_pca\"\n",
    "                else:\n",
    "                    needed = base_name\n",
    "\n",
    "                if needed not in methods_set:\n",
    "                    continue\n",
    "                if obsm_key not in adata.obsm:\n",
    "                    print(f\"[UMAP] skipping {obsm_key}, not in adata.obsm\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"[UMAP] {title} → UMAP({label_key})\")\n",
    "                ad_tmp = adata.copy()\n",
    "                ad_tmp.obsm[\"X_tmp\"] = adata.obsm[obsm_key]\n",
    "\n",
    "                sc.pp.neighbors(\n",
    "                    ad_tmp,\n",
    "                    n_neighbors=n_neighbors,\n",
    "                    use_rep=\"X_tmp\",\n",
    "                    random_state=seed,\n",
    "                )\n",
    "                sc.tl.umap(ad_tmp, min_dist=umap_min_dist, random_state=seed)\n",
    "\n",
    "                sc.pl.umap(\n",
    "                    ad_tmp,\n",
    "                    color=label_key,\n",
    "                    title=f\"{title} → UMAP ({label_key})\",\n",
    "                    frameon=False,\n",
    "                    show=True,\n",
    "                )\n",
    "\n",
    "    return adata, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333118e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_embeddings(\n",
    "    embeddings: dict[str, np.ndarray],\n",
    "    labels: np.ndarray,\n",
    "    n_clusters: int,\n",
    "    n_seeds: int = 10,\n",
    "    seed: int = 0,\n",
    "    ari_k: int = 10,\n",
    "    plot: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate a dict of embeddings via KMeans + ARI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dict[str, np.ndarray]\n",
    "        Mapping from method name -> embedding array (n_cells x d).\n",
    "    labels : np.ndarray\n",
    "        Ground-truth labels (length n_cells).\n",
    "    n_clusters : int\n",
    "        Number of clusters for KMeans (typically == # unique labels).\n",
    "    n_seeds : int\n",
    "        Number of KMeans random seeds to use for each embedding.\n",
    "    seed : int\n",
    "        Base random seed; seeds used are seed, seed+1, ..., seed+n_seeds-1.\n",
    "    ari_k : int\n",
    "        Number of leading dimensions to use from each embedding.\n",
    "    plot : bool\n",
    "        If True, show a bar plot of mean ARI with error bars (± std).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Columns: [\"method\", \"mean_ari\", \"std_ari\"] sorted by mean_ari desc.\n",
    "    \"\"\"\n",
    "    rows: list[dict[str, float | str]] = []\n",
    "\n",
    "    for name, emb in embeddings.items():\n",
    "        emb = np.asarray(emb)\n",
    "        if emb.ndim != 2:\n",
    "            print(f\"[evaluate_embeddings] skipping {name}: emb.ndim={emb.ndim}\")\n",
    "            continue\n",
    "        if emb.shape[0] != labels.shape[0]:\n",
    "            print(\n",
    "                f\"[evaluate_embeddings] skipping {name}: \"\n",
    "                f\"n_cells mismatch (emb={emb.shape[0]}, labels={labels.shape[0]})\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        k_eff = min(ari_k, emb.shape[1])\n",
    "        X_use = emb[:, :k_eff]\n",
    "\n",
    "        scores = []\n",
    "        for s in range(seed, seed + n_seeds):\n",
    "            km = KMeans(n_clusters=n_clusters, n_init=10, random_state=s)\n",
    "            km.fit(X_use)\n",
    "            ari = adjusted_rand_score(labels, km.labels_)\n",
    "            scores.append(ari)\n",
    "\n",
    "        scores = np.asarray(scores, float)\n",
    "        mean_ari = float(scores.mean())\n",
    "        std_ari = float(scores.std())\n",
    "\n",
    "        print(f\"[ARI] {name:15s}: mean={mean_ari:0.4f}, std={std_ari:0.4f}\")\n",
    "        rows.append({\"method\": name, \"mean_ari\": mean_ari, \"std_ari\": std_ari})\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"[evaluate_embeddings] No valid embeddings to evaluate.\")\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values(\"mean_ari\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.bar(df[\"method\"], df[\"mean_ari\"], yerr=df[\"std_ari\"], capsize=4)\n",
    "        ax.set_ylabel(\"Adjusted Rand Index\")\n",
    "        ax.set_title(f\"Clustering ARI across embeddings (k={ari_k}, seeds={n_seeds})\")\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7ae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00523b224c048988b1af6f14ca3a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/9.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prep_for_manifolds] running Scanpy QC metrics\n",
      "n_obs, n_vars (pre-HVG): 2730 3451\n",
      "Means finite? True\n",
      "Means min/max: 0.0043956046 26.31099\n",
      "# non-finite means: 0\n",
      "n_obs, n_vars (post-HVG): 2730 2000\n",
      "[Energy DSM] Epoch 1/50  loss=0.0000\n",
      "[Energy DSM] Epoch 2/50  loss=0.0000\n",
      "[Energy DSM] Epoch 3/50  loss=0.0000\n",
      "[Energy DSM] Epoch 4/50  loss=0.0000\n",
      "[Energy DSM] Epoch 5/50  loss=0.0000\n",
      "[Energy DSM] Epoch 6/50  loss=0.0000\n",
      "[Energy DSM] Epoch 7/50  loss=0.0000\n",
      "[Energy DSM] Epoch 8/50  loss=0.0000\n",
      "[Energy DSM] Epoch 9/50  loss=0.0000\n",
      "[Energy DSM] Epoch 10/50  loss=0.0000\n",
      "[Energy DSM] Epoch 11/50  loss=0.0000\n",
      "[Energy DSM] Epoch 12/50  loss=0.0000\n",
      "[Energy DSM] Epoch 13/50  loss=0.0000\n",
      "[Energy DSM] Epoch 14/50  loss=0.0000\n",
      "[Energy DSM] Epoch 15/50  loss=0.0000\n",
      "[Energy DSM] Epoch 16/50  loss=0.0000\n",
      "[Energy DSM] Epoch 17/50  loss=0.0000\n",
      "[Energy DSM] Epoch 18/50  loss=0.0000\n",
      "[Energy DSM] Epoch 19/50  loss=0.0000\n",
      "[Energy DSM] Epoch 20/50  loss=0.0000\n",
      "[Energy DSM] Epoch 21/50  loss=0.0000\n",
      "[Energy DSM] Epoch 22/50  loss=0.0000\n",
      "[Energy DSM] Epoch 23/50  loss=0.0000\n",
      "[Energy DSM] Epoch 24/50  loss=0.0000\n",
      "[Energy DSM] Epoch 25/50  loss=0.0000\n",
      "[Energy DSM] Epoch 26/50  loss=0.0000\n",
      "[Energy DSM] Epoch 27/50  loss=0.0000\n",
      "[Energy DSM] Epoch 28/50  loss=0.0000\n",
      "[Energy DSM] Epoch 29/50  loss=0.0000\n",
      "[Energy DSM] Epoch 30/50  loss=0.0000\n",
      "[Energy DSM] Epoch 31/50  loss=0.0000\n",
      "[Energy DSM] Epoch 32/50  loss=0.0000\n",
      "[Energy DSM] Epoch 33/50  loss=0.0000\n",
      "[Energy DSM] Epoch 34/50  loss=0.0000\n",
      "[Energy DSM] Epoch 35/50  loss=0.0000\n",
      "[Energy DSM] Epoch 36/50  loss=0.0000\n",
      "[Energy DSM] Epoch 37/50  loss=0.0000\n",
      "[Energy DSM] Epoch 38/50  loss=0.0000\n",
      "[Energy DSM] Epoch 39/50  loss=0.0000\n",
      "[Energy DSM] Epoch 40/50  loss=0.0000\n",
      "[Energy DSM] Epoch 41/50  loss=0.0000\n",
      "[Energy DSM] Epoch 42/50  loss=0.0000\n",
      "[Energy DSM] Epoch 43/50  loss=0.0000\n",
      "[Energy DSM] Epoch 44/50  loss=0.0000\n",
      "[Energy DSM] Epoch 45/50  loss=0.0000\n",
      "[Energy DSM] Epoch 46/50  loss=0.0000\n",
      "[Energy DSM] Epoch 47/50  loss=0.0000\n",
      "[Energy DSM] Epoch 48/50  loss=0.0000\n",
      "[Energy DSM] Epoch 49/50  loss=0.0000\n",
      "[Energy DSM] Epoch 50/50  loss=0.0000\n",
      "[EGGFM DiffMap] X shape: (2730, 2000)\n",
      "[EGGFM DiffMap] building kNN graph (euclidean for neighbor selection)...\n",
      "[EGGFM DiffMap] total edges (directed): 109200\n",
      "[EGGFM DiffMap] computing Hessian-based edge lengths in batches...\n",
      "  processed batch 27/27 (109200 / 109200 edges)\n",
      "[EGGFM DiffMap] q_low=0.08025, q_hi=0.2095, eps=0.1341\n",
      "[EGGFM DiffMap] computing eigenvectors...\n",
      "[EGGFM DiffMap] finished. Embedding shape: (2730, 30)\n",
      "[ARI] eggfm_best     : mean=0.2139, std=0.0305\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cd10b3df-1962-4162-89f7-c83de535d551\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean_ari</th>\n",
       "      <th>std_ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eggfm_best</td>\n",
       "      <td>0.213856</td>\n",
       "      <td>0.030524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd10b3df-1962-4162-89f7-c83de535d551')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cd10b3df-1962-4162-89f7-c83de535d551 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cd10b3df-1962-4162-89f7-c83de535d551');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       method  mean_ari   std_ari\n",
       "0  eggfm_best  0.213856  0.030524"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import copy\n",
    "\n",
    "# params = {\n",
    "#     \"seed\": 7,\n",
    "#     \"hvg_n_top_genes\": 2000,\n",
    "#     \"spec\": {\n",
    "#         \"n_pcs\": 20,\n",
    "#         \"dcol_max_cells\": 3000,\n",
    "#         \"ari_label_key\": \"Cell type annotation\",  # must match adata.obs column\n",
    "#         \"ari_n_dims\": 10,\n",
    "#     },\n",
    "#     \"qc\": {\n",
    "#         \"min_cells\": 500,\n",
    "#         \"min_genes\": 200,\n",
    "#         \"max_pct_mt\": 15,\n",
    "#     },\n",
    "#     \"eggfm_model\": {\n",
    "#         \"hidden_dims\": [512, 512, 512, 512],\n",
    "#     },\n",
    "#     \"eggfm_train\": {\n",
    "#         \"batch_size\": 4096,\n",
    "#         \"num_epochs\": 50,\n",
    "#         \"lr\": 1e-4,\n",
    "#         \"sigma\": 0.1,\n",
    "#         \"device\": \"cuda\",\n",
    "#     },\n",
    "#     \"eggfm_diffmap\": {\n",
    "#         \"n_neighbors\": 10,\n",
    "#         \"n_comps\": 30,\n",
    "#         \"device\": \"cuda\",\n",
    "#         \"hvp_mode\": \"vHv\",\n",
    "#         \"hvp_batch_size\": 4096,\n",
    "#         \"eps_mode\": \"median\",\n",
    "#         \"eps_value\": 1.0,\n",
    "#         \"t\": 1.0,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "\n",
    "# # 1) Load data\n",
    "# adata = sc.datasets.paul15()\n",
    "\n",
    "# # 2) Preprocess in a way that mirrors your real Weinreb prep\n",
    "# adata = prep_for_manifolds(\n",
    "#     adata,\n",
    "#     min_genes=params[\"qc\"][\"min_genes\"],\n",
    "#     hvg_n_top_genes=2000,\n",
    "# )\n",
    "\n",
    "# # 3) Compute manifolds + UMAPs using DCOL, Diffmap(PCA/DCOL/EGGFM), PHATE, scVI\n",
    "\n",
    "\n",
    "# label_key = \"paul15_clusters\"\n",
    "# labels = adata.obs[label_key].to_numpy()\n",
    "# n_clusters = np.unique(labels).size\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # Ablation grids (per-family, not all combined)\n",
    "# # -------------------------------------------------------------------\n",
    "# abl_n_neighbors = [10, 20, 40, 60]\n",
    "# abl_t = [0.5, 1.0, 2.0, 4.0]\n",
    "# abl_hvp_mode = [\"Hv_norm2\", \"vHv\"]\n",
    "# abl_sigma = [0.05, 0.1, 0.2]\n",
    "# abl_hidden = [\n",
    "#     [256, 256, 256, 256],\n",
    "#     [512, 512],\n",
    "#     [512, 512, 512, 512, 512, 512],\n",
    "# ]\n",
    "# abl_lr = [5e-4, 1e-3, 2e-3]\n",
    "# abl_batch_size = [1024, 4096]\n",
    "\n",
    "# results = []\n",
    "\n",
    "\n",
    "# # Helper to run one config and append to results\n",
    "# def run_single_eggfm_ablation(\n",
    "#     adata: sc.AnnData,\n",
    "#     params: dict,\n",
    "#     labels: np.ndarray,\n",
    "#     n_clusters: int,\n",
    "#     ari_k: int,\n",
    "#     tag: str,\n",
    "#     meta: dict,\n",
    "# ):\n",
    "#     # Copy AnnData so we don't accumulate neighbors/umaps/etc\n",
    "#     ad = adata.copy()\n",
    "#     ad, emb_dict = compute_manifolds(\n",
    "#         ad,\n",
    "#         params,\n",
    "#         n_pcs=ari_k,\n",
    "#         seed=params.get(\"seed\", 0),\n",
    "#         label_key=None,  # no plotting here\n",
    "#         n_neighbors=params[\"eggfm_diffmap\"][\"n_neighbors\"],\n",
    "#         methods=[\"diffmap_eggfm\"],  # only EGGFM\n",
    "#     )\n",
    "\n",
    "#     if \"diffmap_eggfm\" not in emb_dict:\n",
    "#         print(f\"[ablation] no diffmap_eggfm produced for tag={tag}, skipping\")\n",
    "#         return\n",
    "\n",
    "#     emb_name = f\"eggfm_{tag}\"\n",
    "#     df = evaluate_embeddings(\n",
    "#         embeddings={emb_name: emb_dict[\"diffmap_eggfm\"]},\n",
    "#         labels=labels,\n",
    "#         n_clusters=n_clusters,\n",
    "#         n_seeds=10,\n",
    "#         seed=0,\n",
    "#         ari_k=ari_k,\n",
    "#         plot=False,\n",
    "#     )\n",
    "#     # attach metadata columns\n",
    "#     for k, v in meta.items():\n",
    "#         df[k] = v\n",
    "#     df[\"tag\"] = tag\n",
    "#     results.append(df)\n",
    "\n",
    "\n",
    "# ari_k = params[\"spec\"][\"ari_n_dims\"]\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 1) n_neighbors ablation\n",
    "# # -------------------------------------------------------------------\n",
    "# for nn_abln in abl_n_neighbors:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_diffmap\"][\"n_neighbors\"] = nn_abln\n",
    "#     tag = f\"nnb{nn_abln}\"\n",
    "#     meta = {\"group\": \"n_neighbors\", \"n_neighbors\": nn_abln}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 2) diffusion time t\n",
    "# # -------------------------------------------------------------------\n",
    "# for t in abl_t:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_diffmap\"][\"t\"] = t\n",
    "#     tag = f\"t{t}\"\n",
    "#     meta = {\"group\": \"t\", \"t\": t}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 3) hvp_mode: Hv_norm2 vs vHv\n",
    "# # -------------------------------------------------------------------\n",
    "# for mode in abl_hvp_mode:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_diffmap\"][\"hvp_mode\"] = mode\n",
    "#     tag = f\"hvp_{mode}\"\n",
    "#     meta = {\"group\": \"hvp_mode\", \"hvp_mode\": mode}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 4) sigma in DSM\n",
    "# # -------------------------------------------------------------------\n",
    "# for sigma in abl_sigma:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_train\"][\"sigma\"] = sigma\n",
    "#     tag = f\"sigma{sigma}\"\n",
    "#     meta = {\"group\": \"sigma\", \"sigma\": sigma}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 5) hidden_dims capacity\n",
    "# # -------------------------------------------------------------------\n",
    "# for hd in abl_hidden:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_model\"][\"hidden_dims\"] = hd\n",
    "#     tag = \"hd_\" + \"x\".join(str(h) for h in hd)\n",
    "#     meta = {\"group\": \"hidden_dims\", \"hidden_dims\": str(hd)}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 6) learning rate\n",
    "# # -------------------------------------------------------------------\n",
    "# for lr in abl_lr:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_train\"][\"lr\"] = lr\n",
    "#     tag = f\"lr{lr}\"\n",
    "#     meta = {\"group\": \"lr\", \"lr\": lr}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # 7) batch size\n",
    "# # -------------------------------------------------------------------\n",
    "# for bs in abl_batch_size:\n",
    "#     params = copy.deepcopy(params)\n",
    "#     params[\"eggfm_train\"][\"batch_size\"] = bs\n",
    "#     tag = f\"bs{bs}\"\n",
    "#     meta = {\"group\": \"batch_size\", \"batch_size\": bs}\n",
    "#     run_single_eggfm_ablation(adata, params, labels, n_clusters, ari_k, tag, meta)\n",
    "\n",
    "# # -------------------------------------------------------------------\n",
    "# # Prettyyy\n",
    "# # -------------------------------------------------------------------\n",
    "# # from IPython.display import display\n",
    "\n",
    "# if len(results) > 0:\n",
    "#     all_results = pd.concat(results, ignore_index=True)\n",
    "#     # display(all_results)  # show full table in the notebook\n",
    "# else:\n",
    "#     all_results = None\n",
    "#     print(\"No ablation results collected.\")\n",
    "\n",
    "# all_results  # last-line expression: shows the DF or None\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "# ---- 0) Base params (your current dict) ----\n",
    "params = {\n",
    "    \"seed\": 7,\n",
    "    \"hvg_n_top_genes\": 2000,\n",
    "    \"spec\": {\n",
    "        \"n_pcs\": 20,\n",
    "        \"dcol_max_cells\": 3000,\n",
    "        \"ari_label_key\": \"Cell type annotation\",\n",
    "        \"ari_n_dims\": 10,\n",
    "    },\n",
    "    \"qc\": {\n",
    "        \"min_cells\": 500,\n",
    "        \"min_genes\": 200,\n",
    "        \"max_pct_mt\": 15,\n",
    "    },\n",
    "    \"eggfm_model\": {\n",
    "        \"hidden_dims\": [512, 512, 512, 512],\n",
    "    },\n",
    "    \"eggfm_train\": {\n",
    "        \"batch_size\": 4096,\n",
    "        \"num_epochs\": 50,\n",
    "        \"lr\": 1e-4,\n",
    "        \"sigma\": 0.1,\n",
    "        \"device\": \"cuda\",\n",
    "    },\n",
    "    \"eggfm_diffmap\": {\n",
    "        \"n_neighbors\": 10,\n",
    "        \"n_comps\": 30,\n",
    "        \"device\": \"cuda\",\n",
    "        \"hvp_mode\": \"vHv\",\n",
    "        \"hvp_batch_size\": 4096,\n",
    "        \"eps_mode\": \"median\",\n",
    "        \"eps_value\": 1.0,\n",
    "        \"t\": 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# ---- 1) Override with best-found hyperparams ----\n",
    "best_params = copy.deepcopy(params)\n",
    "\n",
    "best_params[\"eggfm_diffmap\"][\"n_neighbors\"] = 40  # best from ablation\n",
    "best_params[\"eggfm_diffmap\"][\"t\"] = 0.5  # best t\n",
    "best_params[\"eggfm_diffmap\"][\"hvp_mode\"] = \"Hv_norm2\"  # best HVP mode\n",
    "\n",
    "# keep hidden_dims as [512,512,512,512]\n",
    "best_params[\"eggfm_model\"][\"hidden_dims\"] = [512, 512, 512, 512]\n",
    "\n",
    "# DSM hyperparams\n",
    "best_params[\"eggfm_train\"][\"sigma\"] = 0.1\n",
    "best_params[\"eggfm_train\"][\"lr\"] = 1e-3  # bump back up to 1e-3\n",
    "best_params[\"eggfm_train\"][\"batch_size\"] = 4096\n",
    "\n",
    "# ---- 2) Load and preprocess paul15 ----\n",
    "adata = sc.datasets.paul15()\n",
    "\n",
    "adata = prep_for_manifolds(\n",
    "    adata,\n",
    "    min_genes=best_params[\"qc\"][\"min_genes\"],\n",
    "    hvg_n_top_genes=best_params[\"hvg_n_top_genes\"],\n",
    ")\n",
    "\n",
    "label_key = \"paul15_clusters\"\n",
    "labels = adata.obs[label_key].to_numpy()\n",
    "n_clusters = np.unique(labels).size\n",
    "ari_k = best_params[\"spec\"][\"ari_n_dims\"]\n",
    "\n",
    "# ---- 3) Run only EGGFM Diffmap with these params ----\n",
    "adata_best, emb_dict = compute_manifolds(\n",
    "    adata,\n",
    "    best_params,\n",
    "    n_pcs=ari_k,\n",
    "    seed=best_params[\"seed\"],\n",
    "    label_key=None,  # set to label_key if you also want UMAP plots\n",
    "    n_neighbors=best_params[\"eggfm_diffmap\"][\"n_neighbors\"],\n",
    "    methods=[\"diffmap_eggfm\"],  # only EGGFM manifold\n",
    "    umap_plot=False,  # or True if your version supports it\n",
    ")\n",
    "\n",
    "if \"diffmap_eggfm\" not in emb_dict:\n",
    "    raise RuntimeError(\n",
    "        \"diffmap_eggfm embedding not produced; check run_eggfm_dimred wiring.\"\n",
    "    )\n",
    "\n",
    "# ---- 4) Evaluate ARI for this single config ----\n",
    "df_best = evaluate_embeddings(\n",
    "    embeddings={\"eggfm_best\": emb_dict[\"diffmap_eggfm\"]},\n",
    "    labels=labels,\n",
    "    n_clusters=n_clusters,\n",
    "    n_seeds=10,\n",
    "    seed=0,\n",
    "    ari_k=ari_k,\n",
    "    plot=True,  # set False if you don’t want the bar plot\n",
    ")\n",
    "\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d71800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata_paul15, paul15_embeddings, paul15_df = run_paul15_manifold_panel(\n",
    "#     out=\"out/paul15_dimred_summary.csv\",\n",
    "#     n_top_genes=2000,\n",
    "#     n_pcs=50,\n",
    "#     seed=0,\n",
    "#     n_seeds=10,\n",
    "# )\n",
    "\n",
    "# Example for Paul15\n",
    "# labels_cat = adata.obs[\"paul15_clusters\"].astype(\"category\")\n",
    "# labels = labels_cat.cat.codes.to_numpy()\n",
    "# n_clusters = labels_cat.cat.categories.size\n",
    "\n",
    "# df_ari = evaluate_embeddings(\n",
    "#     embeddings,\n",
    "#     labels=labels,\n",
    "#     n_clusters=n_clusters,\n",
    "#     n_seeds=10,\n",
    "#     seed=0,\n",
    "#     ari_k=10,\n",
    "#     plot=False,\n",
    "# )\n",
    "# df_ari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
